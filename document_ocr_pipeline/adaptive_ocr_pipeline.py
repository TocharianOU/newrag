#!/usr/bin/env python3
"""
è‡ªé€‚åº”ä¸¤é˜¶æ®µ OCR æµæ°´çº¿
1. ç¬¬ä¸€é˜¶æ®µï¼š300 DPI å…¨å±€è¯†åˆ«
2. ç¬¬äºŒé˜¶æ®µï¼šå¯¹ä½ç½®ä¿¡åº¦åŒºåŸŸå±€éƒ¨æ”¾å¤§ï¼ˆ600 DPIï¼‰
3. è¾“å‡ºå®Œæ•´çš„å¤šå±‚æ¬¡ç»“æœ
"""
import sys
import os
import json
import subprocess
from pathlib import Path
import cv2
import numpy as np


class AdaptiveOCRPipeline:
    """è‡ªé€‚åº” OCR å¤„ç†æµæ°´çº¿"""
    
    def __init__(self, ocr_engine='easy', confidence_threshold=0.7):
        """
        Args:
            ocr_engine: OCR å¼•æ“ (vision/paddle/easy)
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„åŒºåŸŸéœ€è¦é‡æ–°è¯†åˆ«
        """
        self.ocr_engine = ocr_engine
        self.confidence_threshold = confidence_threshold
        
        # è„šæœ¬è·¯å¾„
        script_dir = Path("document_ocr_pipeline")
        self.extract_script = script_dir / "extract_document.py"
        self.visualize_script = script_dir / "visualize_extraction.py"
    
    def process_page(self, page, page_num, output_dir):
        """å¤„ç†å•ä¸ªé¡µé¢"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        print(f"{'='*80}")
        print(f"ğŸ“„ Page {page_num} - Adaptive OCR Pipeline")
        print(f"{'='*80}")
        
        # ============ é˜¶æ®µ1ï¼šå…¨å±€è¯†åˆ« (300 DPI) ============
        print(f"\nğŸ” Stage 1: Global Recognition (300 DPI)")
        print("-" * 80)
        
        # 1.1 è½¬æ¢ä¸º 300 DPI å›¾ç‰‡
        print(f"[1.1] Converting to 300 DPI...")
        img_300 = page.to_image(resolution=300)
        img_300_array = np.array(img_300.original)
        img_300_path = output_path / f"page_{page_num:03d}_300dpi.png"
        cv2.imwrite(str(img_300_path), cv2.cvtColor(img_300_array, cv2.COLOR_RGB2BGR),
                   [cv2.IMWRITE_PNG_COMPRESSION, 3])
        print(f"      âœ“ Saved: {img_300_path.name}")
        
        # 1.2 å…¨å±€ OCR
        print(f"[1.2] Running global OCR...")
        ocr_global_json = output_path / f"page_{page_num:03d}_global_ocr.json"
        subprocess.run([
            sys.executable,
            str(self.extract_script),
            str(img_300_path),
            "--ocr-engine", self.ocr_engine,
            "-o", str(ocr_global_json)
        ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        print(f"      âœ“ Saved: {ocr_global_json.name}")
        
        # 1.3 å¯è§†åŒ–å…¨å±€ç»“æœ
        print(f"[1.3] Creating global visualization...")
        vis_global_png = output_path / f"page_{page_num:03d}_global_visualized.png"
        subprocess.run([
            sys.executable,
            str(self.visualize_script),
            str(img_300_path),
            str(ocr_global_json),
            "-o", str(vis_global_png)
        ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        print(f"      âœ“ Saved: {vis_global_png.name}")
        
        # ============ é˜¶æ®µ2ï¼šåˆ†æä½ç½®ä¿¡åº¦åŒºåŸŸ ============
        print(f"\nğŸ¯ Stage 2: Analyzing Low-Confidence Regions")
        print("-" * 80)
        
        # 2.1 è¯»å– OCR ç»“æœ
        with open(ocr_global_json, 'r', encoding='utf-8') as f:
            ocr_data = json.load(f)
        
        # 2.2 æ‰¾å‡ºä½ç½®ä¿¡åº¦æ–‡æœ¬å—
        low_conf_blocks = []
        for block in ocr_data.get('text_blocks', []):
            if block.get('confidence', 1.0) < self.confidence_threshold:
                low_conf_blocks.append(block)
        
        print(f"[2.1] Found {len(low_conf_blocks)} low-confidence regions (< {self.confidence_threshold})")
        
        if len(low_conf_blocks) == 0:
            print(f"      âœ“ No refinement needed - all text has high confidence!")
            
            # ä»ç„¶éœ€è¦ VLM å¤„ç†
            print(f"\nğŸ¤– Stage 3: VLM Refinement (AI Understanding)")
            print("-" * 80)
            print(f"[3.1] Analyzing with VLM (this may take 10-30 seconds)...")
            
            script_dir = Path("document_ocr_pipeline")
            refine_script = script_dir / "refine_with_vlm.py"
            vlm_json_path = output_path / f"page_{page_num:03d}_vlm.json"
            
            subprocess.run([
                sys.executable,
                str(refine_script),
                str(img_300_path),
                str(ocr_global_json),
                "-o", str(vlm_json_path),
                "-p", str(page_num)
            ], check=True)
            
            print(f"      âœ“ VLM analysis complete: {vlm_json_path.name}")
            
            return self._create_result_summary(page_num, output_path, has_regions=False,
                                              ocr_data=ocr_data, vlm_json=str(vlm_json_path.name))
        
        # 2.3 åŠ¨æ€åˆ‡åˆ†ç­–ç•¥ - åˆå¹¶é‚»è¿‘çš„ä½ç½®ä¿¡åº¦åŒºåŸŸ
        regions = self._merge_nearby_regions(low_conf_blocks, img_300_array.shape)
        print(f"[2.2] Merged into {len(regions)} refinement regions")
        
        # ============ é˜¶æ®µ3ï¼šå±€éƒ¨æ”¾å¤§è¯†åˆ« (600 DPI) ============
        print(f"\nğŸ”¬ Stage 3: Refine Low-Confidence Regions (600 DPI)")
        print("-" * 80)
        
        # 3.1 è½¬æ¢ä¸º 600 DPI å›¾ç‰‡ï¼ˆåªç”¨äºåˆ‡åˆ†ï¼‰
        img_600 = page.to_image(resolution=600)
        img_600_array = np.array(img_600.original)
        
        region_results = []
        for i, region in enumerate(regions, 1):
            region_id = i
            print(f"\n[3.{i}] Processing region {region_id}/{len(regions)}...")
            
            # è®¡ç®— 600 DPI ä¸‹çš„åæ ‡ï¼ˆæ”¾å¤§ 2 å€ï¼‰
            x1 = int(region['x1'] * 2)
            y1 = int(region['y1'] * 2)
            x2 = int(region['x2'] * 2)
            y2 = int(region['y2'] * 2)
            
            # æ·»åŠ è¾¹è·ï¼ˆ10%ï¼‰
            margin_x = int((x2 - x1) * 0.1)
            margin_y = int((y2 - y1) * 0.1)
            x1 = max(0, x1 - margin_x)
            y1 = max(0, y1 - margin_y)
            x2 = min(img_600_array.shape[1], x2 + margin_x)
            y2 = min(img_600_array.shape[0], y2 + margin_y)
            
            # åˆ‡åˆ†åŒºåŸŸ
            region_img = img_600_array[y1:y2, x1:x2]
            
            # ä¿å­˜åŒºåŸŸå›¾ç‰‡
            region_img_path = output_path / f"page_{page_num:03d}_region_{region_id:02d}_600dpi.png"
            cv2.imwrite(str(region_img_path), cv2.cvtColor(region_img, cv2.COLOR_RGB2BGR),
                       [cv2.IMWRITE_PNG_COMPRESSION, 3])
            
            # OCR è¯†åˆ«
            region_ocr_json = output_path / f"page_{page_num:03d}_region_{region_id:02d}_ocr.json"
            subprocess.run([
                sys.executable,
                str(self.extract_script),
                str(region_img_path),
                "--ocr-engine", self.ocr_engine,
                "-o", str(region_ocr_json)
            ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
            # å¯è§†åŒ–
            region_vis_png = output_path / f"page_{page_num:03d}_region_{region_id:02d}_visualized.png"
            subprocess.run([
                sys.executable,
                str(self.visualize_script),
                str(region_img_path),
                str(region_ocr_json),
                "-o", str(region_vis_png)
            ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
            # ç»Ÿè®¡æ”¹è¿›æƒ…å†µ
            with open(region_ocr_json, 'r', encoding='utf-8') as f:
                region_data = json.load(f)
            
            avg_conf = region_data.get('average_confidence', 0)
            text_count = region_data.get('text_blocks_count', 0)
            
            print(f"      âœ“ Region {region_id}: {text_count} blocks, avg confidence: {avg_conf*100:.1f}%")
            
            region_results.append({
                "region_id": region_id,
                "bbox_300dpi": [region['x1'], region['y1'], region['x2'], region['y2']],
                "bbox_600dpi": [x1, y1, x2, y2],
                "image": str(region_img_path.name),
                "ocr_json": str(region_ocr_json.name),
                "visualized": str(region_vis_png.name),
                "text_blocks": text_count,
                "avg_confidence": avg_conf
            })
        
        # ============ é˜¶æ®µ4ï¼šVLM ç²¾ç‚¼ ============
        print(f"\nğŸ¤– Stage 4: VLM Refinement (AI Understanding)")
        print("-" * 80)
        
        # 4.1 è°ƒç”¨ VLM å¤„ç†
        print(f"[4.1] Analyzing with VLM (this may take 10-30 seconds)...")
        script_dir = Path("document_ocr_pipeline")
        refine_script = script_dir / "refine_with_vlm.py"
        vlm_json_path = output_path / f"page_{page_num:03d}_vlm.json"
        
        subprocess.run([
            sys.executable,
            str(refine_script),
            str(img_300_path),
            str(ocr_global_json),
            "-o", str(vlm_json_path),
            "-p", str(page_num)
        ], check=True)
        
        print(f"      âœ“ VLM analysis complete: {vlm_json_path.name}")
        
        # ============ ç”Ÿæˆæ±‡æ€»ç»“æœ ============
        print(f"\nğŸ“Š Generating Summary")
        print("-" * 80)
        
        return self._create_result_summary(page_num, output_path, 
                                          has_regions=True, 
                                          region_results=region_results,
                                          ocr_data=ocr_data,
                                          vlm_json=str(vlm_json_path.name))
    
    def _merge_nearby_regions(self, blocks, img_shape, merge_threshold=50):
        """åˆå¹¶é‚»è¿‘çš„ä½ç½®ä¿¡åº¦åŒºåŸŸ"""
        if not blocks:
            return []
        
        height, width = img_shape[:2]
        regions = []
        
        # ç®€å•ç­–ç•¥ï¼šæŒ‰å¯†åº¦åˆ’åˆ†åŒºåŸŸ
        # å°†å›¾ç‰‡åˆ†æˆç½‘æ ¼ï¼Œç»Ÿè®¡æ¯ä¸ªç½‘æ ¼çš„ä½ç½®ä¿¡åº¦æ–‡æœ¬å—æ•°é‡
        grid_size = 4
        grid = [[[] for _ in range(grid_size)] for _ in range(grid_size)]
        
        for block in blocks:
            bbox = block.get('bbox', [0, 0, width, height])
            center_x = (bbox[0] + bbox[2]) / 2
            center_y = (bbox[1] + bbox[3]) / 2
            
            grid_x = min(int(center_x / width * grid_size), grid_size - 1)
            grid_y = min(int(center_y / height * grid_size), grid_size - 1)
            
            grid[grid_y][grid_x].append(block)
        
        # æ‰¾å‡ºæœ‰æ–‡æœ¬çš„ç½‘æ ¼ï¼Œåˆ›å»ºåŒºåŸŸ
        for i in range(grid_size):
            for j in range(grid_size):
                if len(grid[i][j]) > 0:
                    # è®¡ç®—è¿™ä¸ªç½‘æ ¼çš„è¾¹ç•Œ
                    x1 = j * width // grid_size
                    y1 = i * height // grid_size
                    x2 = (j + 1) * width // grid_size
                    y2 = (i + 1) * height // grid_size
                    
                    regions.append({
                        'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,
                        'block_count': len(grid[i][j])
                    })
        
        return regions
    
    def _create_result_summary(self, page_num, output_path, has_regions=False, 
                               region_results=None, ocr_data=None, vlm_json=None):
        """åˆ›å»ºé¡µé¢å¤„ç†ç»“æœæ‘˜è¦"""
        summary = {
            "page_number": page_num,
            "stage1_global": {
                "resolution": "300 DPI",
                "image": f"page_{page_num:03d}_300dpi.png",
                "ocr_json": f"page_{page_num:03d}_global_ocr.json",
                "visualized": f"page_{page_num:03d}_global_visualized.png",
            }
        }
        
        if has_regions and region_results:
            summary["stage2_refined_regions"] = region_results
            summary["total_refined_regions"] = len(region_results)
        else:
            summary["stage2_refined_regions"] = []
            summary["total_refined_regions"] = 0
        
        if ocr_data:
            summary["statistics"] = {
                "total_text_blocks": len(ocr_data.get('text_blocks', [])),
                "average_confidence": ocr_data.get('average_confidence', 0),
                "low_confidence_blocks": len([b for b in ocr_data.get('text_blocks', []) 
                                             if b.get('confidence', 1.0) < self.confidence_threshold])
            }
        
        if vlm_json:
            summary["stage3_vlm"] = {
                "vlm_json": vlm_json
            }
        
        # ä¿å­˜é¡µé¢æ‘˜è¦
        summary_path = output_path / f"page_{page_num:03d}_summary.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"      âœ“ Saved summary: {summary_path.name}")
        
        return summary


def main():
    import argparse
    parser = argparse.ArgumentParser(description="Adaptive two-stage OCR pipeline")
    parser.add_argument("pdf_file", help="Path to PDF file")
    parser.add_argument("--ocr-engine", choices=['vision', 'paddle', 'easy'], default='easy',
                       help="OCR engine: 'easy' (é»˜è®¤), 'paddle' (å¤šæ–¹å‘-æ…¢ä½†å‡†), 'vision' (å¤šè§’åº¦-å¿«ä¸”å‡†)")
    parser.add_argument("--confidence", type=float, default=0.7,
                       help="Confidence threshold for refinement (default: 0.7)")
    parser.add_argument("--output-dir", type=str, default=None,
                       help="Output directory (default: PDF_name_adaptive)")
    
    args = parser.parse_args()
    
    input_file = Path(args.pdf_file).resolve()
    if not input_file.exists():
        print(f"âŒ Error: File not found: {input_file}")
        sys.exit(1)
    
    # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•
    base_dir = Path(__file__).parent.parent
    os.chdir(base_dir)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if args.output_dir:
        output_path = Path(args.output_dir)
    else:
    output_dir = input_file.stem.replace(' ', '_') + "_adaptive"
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("="*80)
    print("ğŸš€ Adaptive Two-Stage OCR Pipeline")
    print("="*80)
    print(f"Source: {input_file.name}")
    print(f"OCR Engine: {args.ocr_engine.upper()}")
    print(f"Confidence Threshold: {args.confidence}")
    print(f"Output: {output_path}/")
    print()
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import pdfplumber
    except ImportError:
        print("âŒ Missing pdfplumber. Install: pip install pdfplumber")
        sys.exit(1)
    
    # åˆå§‹åŒ–æµæ°´çº¿
    pipeline = AdaptiveOCRPipeline(
        ocr_engine=args.ocr_engine,
        confidence_threshold=args.confidence
    )
    
    # å¤„ç† PDF
    all_pages_summary = []
    
    with pdfplumber.open(input_file) as pdf:
        total_pages = len(pdf.pages)
        print(f"ğŸ“š Total pages: {total_pages}\n")
        
        for page_num, page in enumerate(pdf.pages, 1):
            summary = pipeline.process_page(page, page_num, output_path)
            all_pages_summary.append(summary)
            print()
    
    # ç”Ÿæˆå®Œæ•´æ–‡æ¡£æ‘˜è¦
    print("="*80)
    print("ğŸ“„ Generating Complete Document Summary")
    print("="*80)
    
    complete_summary = {
        "source_file": str(input_file),
        "total_pages": total_pages,
        "ocr_engine": args.ocr_engine,
        "confidence_threshold": args.confidence,
        "pages": all_pages_summary
    }
    
    complete_json = output_path / "complete_adaptive_ocr.json"
    with open(complete_json, 'w', encoding='utf-8') as f:
        json.dump(complete_summary, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ Saved: {complete_json.name}")
    
    # ç”Ÿæˆå®Œæ•´æ–‡æ¡£ JSONï¼ˆVLM ç²¾ç‚¼ç»“æœï¼‰
    print("\nğŸ“„ Generating Complete Document JSON (VLM Refined)")
    print("-" * 80)
    
    pages_array = []
    for page_data in all_pages_summary:
        page_num = page_data["page_number"]
        vlm_json_file = output_path / f"page_{page_num:03d}_vlm.json"
        
        if vlm_json_file.exists():
            with open(vlm_json_file, 'r', encoding='utf-8') as f:
                vlm_result = json.load(f)
                
                # æ·»åŠ æ–‡æ¡£çº§å…ƒæ•°æ®
                page_obj = vlm_result.copy()
                page_obj["source_file"] = str(input_file)
                page_obj["source_file_name"] = input_file.name
                page_obj["output_directory"] = str(output_path.resolve())
                page_obj["total_pages"] = total_pages
                page_obj["ocr_engine"] = args.ocr_engine
                page_obj["ocr_confidence_threshold"] = args.confidence
                
                pages_array.append(page_obj)
    
    complete_document_json = output_path / "complete_document.json"
    with open(complete_document_json, 'w', encoding='utf-8') as f:
        json.dump(pages_array, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ Saved: {complete_document_json.name}")
    print()
    print("="*80)
    print("âœ… Processing Complete!")
    print("="*80)
    print(f"ğŸ“ Output directory: {output_path.absolute()}")
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶ç»“æ„ï¼š")
    print(f"  é˜¶æ®µ1 - å…¨å±€è¯†åˆ« (300 DPI):")
    print(f"    - page_XXX_300dpi.png")
    print(f"    - page_XXX_global_ocr.json")
    print(f"    - page_XXX_global_visualized.png")
    print(f"  é˜¶æ®µ2 - å±€éƒ¨ç²¾ç‚¼ (600 DPI):")
    print(f"    - page_XXX_region_NN_600dpi.png")
    print(f"    - page_XXX_region_NN_ocr.json")
    print(f"    - page_XXX_region_NN_visualized.png")
    print(f"  é˜¶æ®µ3 - VLM ç²¾ç‚¼:")
    print(f"    - page_XXX_vlm.json (AI ç†è§£åçš„å®Œæ•´ç»“æ„åŒ– JSON)")
    print(f"  é¡µé¢æ‘˜è¦:")
    print(f"    - page_XXX_summary.json")
    print(f"  å®Œæ•´æ–‡æ¡£:")
    print(f"    - complete_adaptive_ocr.json (OCR æŠ€æœ¯æ‘˜è¦)")
    print(f"    - complete_document.json (æœ€ç»ˆç»“æœ - JSON List æ ¼å¼)")


if __name__ == "__main__":
    main()


#!/usr/bin/env python3
"""
PPTX å®Œæ•´å¤„ç†ç®¡é“
ç”Ÿæˆä¸ PDF æµç¨‹ä¸€è‡´çš„è¾“å‡ºç»“æ„
"""

import sys
import json
import argparse
from pathlib import Path
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE
import io
from PIL import Image
import subprocess
import re

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from document_ocr_pipeline.extract_document import DocumentExtractor
from document_ocr_pipeline.visualize_extraction import visualize_extraction
from src.utils import get_soffice_command

# å°è¯•å¯¼å…¥ VLM (å¯é€‰ä¾èµ–)
try:
    from src.models import VisionModel
    HAS_VLM = True
except ImportError:
    HAS_VLM = False
    print("âš ï¸  VLM æ¨¡å—æœªå®‰è£…ï¼Œå°†è·³è¿‡æ™ºèƒ½æ–‡æœ¬ä¿®æ­£åŠŸèƒ½")


def detect_problem_content(text_blocks):
    """
    æ£€æµ‹æ˜¯å¦éœ€è¦ VLM ä¿®æ­£
    
    è¿”å›: (éœ€è¦ä¿®æ­£, åŸå› , ç»Ÿè®¡ä¿¡æ¯)
    """
    if not text_blocks:
        return False, "æ— æ–‡æœ¬å—", {}
    
    # ç»Ÿè®¡ä¿¡æ¯
    confidences = [block.get('confidence', 0) for block in text_blocks]
    avg_confidence = sum(confidences) / len(confidences) if confidences else 1.0
    low_conf_count = len([c for c in confidences if c < 0.7])
    low_conf_ratio = low_conf_count / len(confidences) if confidences else 0
    
    all_text = ' '.join([block.get('text', '') for block in text_blocks])
    
    # æ£€æµ‹ç‰¹æ®Šå­—ç¬¦/ä¹±ç 
    garbled_chars = len(re.findall(r'[â–¡â– ï¿½ï¼Ÿ?æ—¬]', all_text))
    garbled_ratio = garbled_chars / max(len(all_text), 1)
    
    # æ£€æµ‹æ–‡ä»¶åˆ—è¡¨ç‰¹å¾
    has_file_extensions = bool(re.search(r'\.(dmg|pkg|tar|gz|zip|app|png|jpg)', all_text, re.IGNORECASE))
    has_tree_symbols = any(char in all_text for char in ['ä¸‰', 'â”œ', 'â””', 'â”‚', 'â”€'])
    has_slash = '/' in all_text
    
    is_file_list = has_file_extensions and (has_tree_symbols or has_slash)
    
    # æ£€æµ‹çŸ­è¡Œå¤šè¡Œç‰¹å¾ï¼ˆæ–‡ä»¶åˆ—è¡¨å…¸å‹ç‰¹å¾ï¼‰
    lines = all_text.split('\n')
    short_lines = [line for line in lines if 0 < len(line.strip()) < 50]
    is_multi_short_lines = len(short_lines) > 5
    
    # æ£€æµ‹æ€ç»´å¯¼å›¾/å…³ç³»å›¾ï¼ˆæ ‘å½¢ç¬¦å·å¯†åº¦ï¼‰
    tree_symbols = sum(all_text.count(s) for s in ['â”œ', 'â””', 'â”‚', 'â”€â”€', 'â”€'])
    arrow_symbols = sum(all_text.count(s) for s in ['â†’', 'â†', 'â†“', 'â†‘', 'â‡’', 'â‡', 'â–¶', 'â—€'])
    is_mindmap = (tree_symbols > 5 or arrow_symbols > 3) and len(text_blocks) > 8
    
    stats = {
        'avg_confidence': avg_confidence,
        'low_conf_ratio': low_conf_ratio,
        'garbled_ratio': garbled_ratio,
        'is_file_list': is_file_list,
        'is_multi_short_lines': is_multi_short_lines,
        'is_mindmap': is_mindmap,
        'tree_symbols_count': tree_symbols,
        'arrow_symbols_count': arrow_symbols
    }
    
    # è§¦å‘æ¡ä»¶ï¼ˆæ»¡è¶³ä»»ä¸€ï¼‰
    # æ³¨é‡Šä¸¥æ ¼æ¡ä»¶ï¼Œé‡‡ç”¨æ›´å®½æ¾çš„ç­–ç•¥è®© VLM æœ‰æœºä¼šä»‹å…¥ä¿®æ­£
    # if avg_confidence < 0.5:  # å¹³å‡ç½®ä¿¡åº¦é˜ˆå€¼
    #     return True, f"å¹³å‡ç½®ä¿¡åº¦è¿‡ä½ ({avg_confidence:.2f})", stats
    # elif garbled_ratio > 0.03:  # ä¹±ç å­—ç¬¦é˜ˆå€¼
    #     return True, f"æ£€æµ‹åˆ°ä¹±ç å­—ç¬¦ ({garbled_ratio:.1%})", stats
    
    # å®½æ¾ä»‹å…¥ç­–ç•¥ï¼ˆ60-80% è¦†ç›–ç‡ï¼‰
    if avg_confidence < 0.8:  # 80% ä»¥ä¸‹å°±ä¿®æ­£
        return True, f"è¯†åˆ«è´¨é‡å¯æå‡ (ç½®ä¿¡åº¦ {avg_confidence:.2f})", stats
    elif garbled_ratio > 0.005:  # 0.5% ä¹±ç å³è§¦å‘
        return True, f"æ£€æµ‹åˆ°ä¹±ç  ({garbled_ratio:.1%})", stats
    elif stats.get('is_mindmap', False):  # æ€ç»´å¯¼å›¾
        return True, "æ£€æµ‹åˆ°æ€ç»´å¯¼å›¾/å…³ç³»å›¾", stats
    elif is_file_list or is_multi_short_lines:  # ç‰¹æ®Šæ ¼å¼
        return True, "æ£€æµ‹åˆ°åˆ—è¡¨ç»“æ„", stats
    
    return False, "è´¨é‡è‰¯å¥½", stats


def refine_text_with_vlm(image_path, ocr_text, vlm_model, context_hint="", confidence_info=None):
    """
    ä½¿ç”¨ VLM ä¿®æ­£ OCR æ–‡æœ¬
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        ocr_text: OCR åŸå§‹æ–‡æœ¬
        vlm_model: VisionModel å®ä¾‹
        context_hint: ä¸Šä¸‹æ–‡æç¤ºï¼ˆå¦‚"æ–‡ä»¶åˆ—è¡¨"ï¼‰
        confidence_info: ç½®ä¿¡åº¦ä¿¡æ¯ dict (avg_confidence, garbled_ratio)
    
    Returns:
        ä¿®æ­£åçš„æ–‡æœ¬
    """
    if not HAS_VLM or not vlm_model:
        return ocr_text
    
    try:
        # æ„å»ºè´¨é‡æç¤ºä¿¡æ¯
        quality_note = ""
        correction_level = ""
        content_type_hint = ""
        if confidence_info:
            avg_conf = confidence_info.get('avg_confidence', 0)
            garbled = confidence_info.get('garbled_ratio', 0)
            is_mindmap = confidence_info.get('is_mindmap', False)
            is_file_list = confidence_info.get('is_file_list', False)
            
            if avg_conf < 0.5:
                quality_note = f"\næ³¨æ„ï¼šOCR è¯†åˆ«è´¨é‡è¾ƒä½ï¼ˆå¹³å‡ç½®ä¿¡åº¦ {avg_conf:.1%}ï¼‰ï¼Œå¯èƒ½å­˜åœ¨è¾ƒå¤šé”™è¯¯ã€‚"
                correction_level = "ã€æ¿€è¿›ä¿®æ­£æ¨¡å¼ã€‘è¯†åˆ«è´¨é‡å¾ˆä½ï¼Œéœ€è¦å¤§å¹…ä¿®æ­£é”™åˆ«å­—å’Œç»“æ„æ ¼å¼"
            elif avg_conf < 0.7:
                correction_level = "ã€ä¸­ç­‰ä¿®æ­£æ¨¡å¼ã€‘é€‚åº¦ä¿®æ­£æ˜æ˜¾çš„é”™åˆ«å­—ï¼Œä¿ç•™å¤§éƒ¨åˆ†åŸæ–‡å’Œç»“æ„æ ¼å¼"
            else:
                correction_level = "ã€ä¿å®ˆä¿®æ­£æ¨¡å¼ã€‘ä»…ä¿®æ­£æ˜æ˜¾é”™è¯¯ï¼Œä¿ç•™æ ¼å¼å’Œè¾¹è·ï¼Œä¿ç•™åŸæœ‰ç»“æ„æ ¼å¼"
            
            if garbled > 0.03:
                quality_note += f"\næ³¨æ„ï¼šæ£€æµ‹åˆ° {garbled:.1%} çš„ä¹±ç å­—ç¬¦ï¼Œè¯·å‚è€ƒå›¾ç‰‡ä¿®æ­£ã€‚"
            
            # å†…å®¹ç±»å‹æç¤º
            if is_mindmap:
                content_type_hint = "\nâš ï¸ **è¿™æ˜¯æ€ç»´å¯¼å›¾/å…³ç³»å›¾**ï¼Œå¿…é¡»ä¿ç•™æ‰€æœ‰å±‚çº§å…³ç³»ã€åˆ†æ”¯ç»“æ„ã€ç®­å¤´æ–¹å‘ï¼"
            elif is_file_list:
                content_type_hint = "\nâš ï¸ **è¿™æ˜¯æ–‡ä»¶åˆ—è¡¨/ç›®å½•**ï¼Œå¿…é¡»ä¿ç•™å±‚çº§ç¼©è¿›å’Œç¬¦å·ï¼"
        
        prompt = f"""è¯·æ ¹æ®å›¾ç‰‡å’Œ OCR è¯†åˆ«ç»“æœï¼Œä¿®æ­£ä»¥ä¸‹æ–‡æœ¬ä¸­çš„é”™è¯¯ï¼š

OCR åŸå§‹ç»“æœï¼š
{ocr_text}

è¯†åˆ«è´¨é‡ä¿¡æ¯ï¼š
{quality_note}
{correction_level}
{content_type_hint}

ä¿®æ­£è¦æ±‚ï¼š
1. **é”™åˆ«å­—ä¿®æ­£**ï¼ˆå¿…é¡»å‚è€ƒå›¾ç‰‡ï¼‰ï¼š
   - å®¹å™¨ç›‘æ§/åº”ç”¨ç›‘æ§/æ•°æ®åº“ç›‘æ§ ç­‰ITæœ¯è¯­
   - å¸¸è§é”™è¯¯ï¼šå®¢å™¨â†’å®¹å™¨ã€ç”³é—´â†’ç©ºé—´ã€Vå¿—â†’æ—¥å¿—ã€ç¦ºâ†’åŸŸ
   - ä¸“æœ‰åè¯ï¼šCyberArkã€Kongã€API Gatewayã€CMDB

2. **æ ¼å¼ä¿ç•™**ï¼ˆç¦æ­¢ä¿®æ”¹ï¼‰ï¼š
   - æ ‘å½¢ç¬¦å·ï¼šâ”œ â”‚ â”” â”€â”€ 
   - ç®­å¤´ç¬¦å·ï¼šâ†’ â† â†“ â†‘ â‡’ â–¶
   - ç¼©è¿›å±‚çº§ï¼šå¿…é¡»ä¸åŸæ–‡ä¸€è‡´
   - æ¢è¡Œä½ç½®ï¼šä¿æŒåŸæœ‰å¸ƒå±€

3. **ç»“æ„ä¿®å¤**ï¼ˆæ€ç»´å¯¼å›¾/å…³ç³»å›¾é‡ç‚¹ï¼‰ï¼š
   - **è¡¥å……ä¸¢å¤±çš„å±‚çº§ç¬¦å·**ï¼ˆ/, -, |, â”œ, â””ï¼‰
   - **æ¢å¤çˆ¶å­å…³ç³»**ï¼ˆå¦‚ A â†’ B â†’ C çš„æµå‘ï¼‰
   - **ä¿æŒåˆ†æ”¯ç»“æ„**ï¼ˆå¤šä¸ªå­èŠ‚ç‚¹å¿…é¡»å…¨éƒ¨å±•ç¤ºï¼‰
   - åˆå¹¶è¢«é”™è¯¯åˆ†å‰²çš„è¯è¯­

4. **ç¦æ­¢è¡Œä¸º**ï¼š
   - ä¸è¦æ·»åŠ åŸå›¾ä¸­æ²¡æœ‰çš„å†…å®¹
   - ä¸è¦æ”¹å˜èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å…³ç³»
   - ä¸è¦åˆå¹¶åº”è¯¥åˆ†å¼€çš„åˆ†æ”¯
   - ä¸è¦åˆ é™¤çœ‹ä¼¼é‡å¤ä½†å®é™…å­˜åœ¨çš„å†…å®¹

{f'æç¤ºï¼šè¿™æ˜¯ä¸€ä¸ª{context_hint}' if context_hint else ''}

è¯·ç›´æ¥è¿”å›ä¿®æ­£åçš„æ–‡æœ¬å†…å®¹ï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šã€‚"""

        result = vlm_model.extract_text_from_image(
            image_path=str(image_path),
            prompt=prompt
        )
        
        refined_text = result.get('text', ocr_text).strip()
        
        # ç®€å•éªŒè¯ï¼šå¦‚æœä¿®æ­£åæ–‡æœ¬å¤ªçŸ­æˆ–å¤ªé•¿ï¼ˆä¸åŸæ–‡ç›¸å·®10å€ï¼‰ï¼Œå¯èƒ½æœ‰é—®é¢˜
        if len(refined_text) < len(ocr_text) * 0.3 or len(refined_text) > len(ocr_text) * 5:
            print(f"      âš ï¸  VLM ä¿®æ­£ç»“æœå¼‚å¸¸ï¼Œä¿æŒåŸæ–‡æœ¬")
            return ocr_text
        
        return refined_text
        
    except Exception as e:
        print(f"      âš ï¸  VLM ä¿®æ­£å¤±è´¥: {e}")
        return ocr_text


def extract_slide_content(slide, slide_num, output_dir, ocr_engine='paddle'):
    """
    æå–å•é¡µå†…å®¹ï¼šæ–‡æœ¬ + å›¾ç‰‡OCR + VLMç»„åˆ
    """
    slide_data = {
        "page_number": slide_num,
        "statistics": {},
        "stage1_global": {},
        "stage3_vlm": {}
    }
    
    # ==================== é˜¶æ®µ 1: æ–‡æœ¬ç›´æ¥æå– ====================
    print(f"\n  ğŸ“ é˜¶æ®µ1: æå–æ–‡æœ¬å†…å®¹ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰...")
    
    extracted_text = {
        "title": "",
        "body": [],
        "notes": "",
        "tables": []
    }
    
    for shape in slide.shapes:
        if shape.has_text_frame:
            text = shape.text.strip()
            if text:
                if hasattr(shape, "is_placeholder") and shape.is_placeholder:
                    placeholder = shape.placeholder_format
                    if placeholder.type == 1:  # Title
                        extracted_text["title"] = text
                    else:
                        extracted_text["body"].append(text)
                else:
                    extracted_text["body"].append(text)
        
        if shape.has_table:
            table = shape.table
            table_data = []
            for row in table.rows:
                row_data = [cell.text for cell in row.cells]
                table_data.append(row_data)
            extracted_text["tables"].append(table_data)
    
    if slide.has_notes_slide:
        extracted_text["notes"] = slide.notes_slide.notes_text_frame.text
    
    # ä¿å­˜æ–‡æœ¬æå–ç»“æœ
    text_json_path = output_dir / f"page_{slide_num:03d}_extracted_text.json"
    with open(text_json_path, 'w', encoding='utf-8') as f:
        json.dump(extracted_text, f, ensure_ascii=False, indent=2)
    
    print(f"    âœ“ æ ‡é¢˜: {extracted_text['title'][:50] if extracted_text['title'] else 'æ— '}")
    print(f"    âœ“ æ–‡æœ¬æ®µè½: {len(extracted_text['body'])} ä¸ª")
    print(f"    âœ“ è¡¨æ ¼: {len(extracted_text['tables'])} ä¸ª")
    
    # ==================== é˜¶æ®µ 1.5: å…¨é¡µ OCR (ç”¨äºè·å–åæ ‡) ====================
    print(f"  ğŸ‘ï¸  é˜¶æ®µ1.5: å…¨é¡µ OCR (è·å–å¸ƒå±€åæ ‡)...")
    
    preview_image = f"page_{slide_num:03d}_300dpi.png"
    preview_path = output_dir / preview_image
    global_ocr_path = output_dir / f"page_{slide_num:03d}_global_ocr.json"
    visualized_image = f"page_{slide_num:03d}_visualized.png"
    visualized_path = output_dir / visualized_image
    
    if preview_path.exists():
        try:
            # å¯¹å…¨é¡µé¢„è§ˆå›¾è¿è¡Œ OCR (300 DPI)
            extractor = DocumentExtractor(ocr_engine=ocr_engine)
            global_ocr_result = extractor.extract_from_image(str(preview_path))
            
            with open(global_ocr_path, 'w', encoding='utf-8') as f:
                json.dump(global_ocr_result, f, ensure_ascii=False, indent=2)
            
            # ç”Ÿæˆå¯è§†åŒ–å›¾
            visualize_extraction(str(preview_path), str(global_ocr_path), str(visualized_path))
            
            print(f"    âœ“ å…¨é¡µ OCR å®Œæˆ: {len(global_ocr_result.get('text_blocks', []))} ä¸ªæ–‡æœ¬å—")
            print(f"    âœ“ åæ ‡æ•°æ®å·²ä¿å­˜: {global_ocr_path.name}")
            
            # ==================== é˜¶æ®µ 1.6: å¤§å­—æ£€æµ‹ä¸ 150 DPI è¡¥å……è¯†åˆ« ====================
            text_blocks = global_ocr_result.get('text_blocks', [])
            if text_blocks:
                # è·å–å›¾ç‰‡å°ºå¯¸
                with Image.open(preview_path) as img:
                    img_width, img_height = img.size
                    img_area = img_width * img_height
                
                # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦ç»Ÿè®¡
                confidences = [block.get('confidence', 0) for block in text_blocks]
                avg_confidence = sum(confidences) / len(confidences) if confidences else 1.0
                low_conf_ratio = len([c for c in confidences if c < 0.7]) / len(confidences) if confidences else 0
                
                # æ£€æµ‹æ˜¯å¦å­˜åœ¨"ç–‘ä¼¼å¤§å­—åŒºåŸŸ"
                large_blocks = []
                for block in text_blocks:
                    bbox = block.get('bbox', [0, 0, 0, 0])
                    if len(bbox) == 4:
                        x1, y1, x2, y2 = bbox
                        block_width = x2 - x1
                        block_height = y2 - y1
                        block_area = block_width * block_height
                        
                        # åˆ¤æ–­æ¡ä»¶ï¼šå•ä¸ªæ–‡å­—å—é¢ç§¯ > å›¾ç‰‡é¢ç§¯çš„ 10%ï¼Œæˆ–å°ºå¯¸ > 300x300 px
                        if block_area > img_area * 0.1 or (block_width > 300 and block_height > 300):
                            large_blocks.append(block)
                
                # è§¦å‘ 150 DPI ç¼©å°è¯†åˆ«çš„æ¡ä»¶ï¼ˆäºŒé€‰ä¸€ï¼‰ï¼š
                # 1. æ£€æµ‹åˆ°å¤§å­—å—
                # 2. æ•´ä½“ç½®ä¿¡åº¦ä½ï¼ˆå¹³å‡ < 0.65 æˆ– è¶…è¿‡ 50% çš„å— < 0.7ï¼‰
                should_try_150dpi = (
                    len(large_blocks) > 0 or 
                    avg_confidence < 0.65 or 
                    low_conf_ratio > 0.5
                )
                
                if should_try_150dpi:
                    if large_blocks:
                        print(f"    ğŸ” æ£€æµ‹åˆ° {len(large_blocks)} ä¸ªå¤§å­—åŒºåŸŸï¼Œå°è¯• 150 DPI ç¼©å°è¯†åˆ«...")
                    else:
                        print(f"    ğŸ” æ•´ä½“ç½®ä¿¡åº¦è¾ƒä½ (å¹³å‡: {avg_confidence:.2f}, ä½ç½®ä¿¡åº¦å æ¯”: {low_conf_ratio:.1%})ï¼Œå°è¯• 150 DPI ç¼©å°è¯†åˆ«...")
                    
                    # ç”Ÿæˆ 150 DPI ç¼©å°ç‰ˆå›¾ç‰‡ï¼ˆç¼©å°åˆ°åŸæ¥çš„ 50%ï¼‰
                    preview_150dpi_path = output_dir / f"page_{slide_num:03d}_preview_150dpi.png"
                    with Image.open(preview_path) as img:
                        new_size = (img_width // 2, img_height // 2)
                        img_150dpi = img.resize(new_size, Image.LANCZOS)
                        img_150dpi.save(preview_150dpi_path)
                    
                    # å¯¹ 150 DPI å›¾ç‰‡è¿è¡Œ OCR
                    ocr_150dpi_result = extractor.extract_from_image(str(preview_150dpi_path))
                    
                    # å°† 150 DPI çš„åæ ‡è¿˜åŸåˆ° 300 DPIï¼ˆåæ ‡ x2ï¼‰
                    for block in ocr_150dpi_result.get('text_blocks', []):
                        if 'bbox' in block and len(block['bbox']) == 4:
                            block['bbox'] = [coord * 2 for coord in block['bbox']]
                    
                    # åˆå¹¶ç»“æœï¼šä¼˜å…ˆä½¿ç”¨é«˜ç½®ä¿¡åº¦çš„
                    merged_blocks = []
                    used_150dpi_indices = set()
                    
                    for block_300 in text_blocks:
                        bbox_300 = block_300.get('bbox', [0, 0, 0, 0])
                        best_match = block_300
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ 150 DPI çš„ç»“æœè¦†ç›–åŒä¸€åŒºåŸŸä¸”ç½®ä¿¡åº¦æ›´é«˜
                        for idx, block_150 in enumerate(ocr_150dpi_result.get('text_blocks', [])):
                            if idx in used_150dpi_indices:
                                continue
                            
                            bbox_150 = block_150.get('bbox', [0, 0, 0, 0])
                            
                            # åˆ¤æ–­ä¸¤ä¸ªæ¡†æ˜¯å¦é‡å ï¼ˆIoU > 0.3ï¼‰
                            x1_300, y1_300, x2_300, y2_300 = bbox_300
                            x1_150, y1_150, x2_150, y2_150 = bbox_150
                            
                            x_overlap = max(0, min(x2_300, x2_150) - max(x1_300, x1_150))
                            y_overlap = max(0, min(y2_300, y2_150) - max(y1_300, y1_150))
                            overlap_area = x_overlap * y_overlap
                            
                            area_300 = (x2_300 - x1_300) * (y2_300 - y1_300)
                            area_150 = (x2_150 - x1_150) * (y2_150 - y1_150)
                            union_area = area_300 + area_150 - overlap_area
                            
                            if union_area > 0:
                                iou = overlap_area / union_area
                                if iou > 0.3:  # é‡å åº¦ > 30%
                                    # ä¼˜å…ˆä½¿ç”¨é«˜ç½®ä¿¡åº¦çš„ç»“æœ
                                    conf_300 = block_300.get('confidence', 0)
                                    conf_150 = block_150.get('confidence', 0)
                                    
                                    if conf_150 > conf_300:
                                        best_match = block_150
                                        used_150dpi_indices.add(idx)
                                    break
                        
                        merged_blocks.append(best_match)
                    
                    # æ·»åŠ æœªåŒ¹é…çš„ 150 DPI ç»“æœ
                    for idx, block_150 in enumerate(ocr_150dpi_result.get('text_blocks', [])):
                        if idx not in used_150dpi_indices:
                            merged_blocks.append(block_150)
                    
                    # æ›´æ–°ç»“æœ
                    improvement_count = len([b for b in merged_blocks if b.get('confidence', 0) > 0.9])
                    original_high_conf = len([b for b in text_blocks if b.get('confidence', 0) > 0.9])
                    
                    if improvement_count > original_high_conf:
                        global_ocr_result['text_blocks'] = merged_blocks
                        with open(global_ocr_path, 'w', encoding='utf-8') as f:
                            json.dump(global_ocr_result, f, ensure_ascii=False, indent=2)
                        
                        # é‡æ–°ç”Ÿæˆå¯è§†åŒ–
                        visualize_extraction(str(preview_path), str(global_ocr_path), str(visualized_path))
                        
                        print(f"    âœ“ 150 DPI è¡¥å……è¯†åˆ«å®Œæˆ: åˆå¹¶å {len(merged_blocks)} ä¸ªæ–‡æœ¬å— (é«˜ç½®ä¿¡åº¦: {original_high_conf} â†’ {improvement_count})")
                    else:
                        print(f"    â„¹ï¸  150 DPI è¯†åˆ«æœªå¸¦æ¥æ˜æ˜¾æ”¹å–„ï¼Œä¿æŒåŸç»“æœ")
                
        except Exception as e:
            print(f"    âš ï¸ å…¨é¡µ OCR å¤±è´¥: {e}")
            # å¦‚æœå¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„ OCR ç»“æœä»¥é˜²æŠ¥é”™
            with open(global_ocr_path, 'w', encoding='utf-8') as f:
                json.dump({"text_blocks": []}, f)
    else:
        print(f"    âš ï¸ é¢„è§ˆå›¾ä¸å­˜åœ¨ï¼Œè·³è¿‡å…¨é¡µ OCR: {preview_path.name}")
    
    # ==================== é˜¶æ®µ 2: å¤„ç†åµŒå…¥å›¾ç‰‡ï¼ˆOCRï¼‰ ====================
    print(f"  ğŸ–¼ï¸  é˜¶æ®µ2: å¤„ç†åµŒå…¥å›¾ç‰‡å†…å®¹...")
    
    images = []
    image_ocr_results = []
    
    for idx, shape in enumerate(slide.shapes, 1):
        if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:
            image = shape.image
            image_filename = f"page_{slide_num:03d}_img_{idx}.{image.ext}"
            image_path = output_dir / image_filename
            
            # ä¿å­˜å›¾ç‰‡
            with open(image_path, "wb") as f:
                f.write(image.blob)
            
            try:
                with Image.open(io.BytesIO(image.blob)) as img:
                    width, height = img.size
                
                images.append({
                    "id": idx,
                    "path": str(image_path),
                    "format": image.ext,
                    "size": [width, height]
                })
                
                print(f"    âœ“ åµŒå…¥å›¾ç‰‡ {idx}: {width}x{height} ({image.ext})")
                
                # å¯¹å›¾ç‰‡è¿è¡Œ OCR
                img_ocr_json_path = output_dir / f"page_{slide_num:03d}_img_{idx}_ocr.json"
                extractor = DocumentExtractor(ocr_engine=ocr_engine)
                ocr_result = extractor.extract_from_image(str(image_path))
                
                with open(img_ocr_json_path, 'w', encoding='utf-8') as f:
                    json.dump(ocr_result, f, ensure_ascii=False, indent=2)
                
                # ç”Ÿæˆå¯è§†åŒ–
                img_vis_path = output_dir / f"page_{slide_num:03d}_img_{idx}_visualized.png"
                visualize_extraction(str(image_path), str(img_ocr_json_path), str(img_vis_path))
                
                image_ocr_results.append({
                    "image_id": idx,
                    "ocr_json": str(img_ocr_json_path),
                    "visualized": str(img_vis_path),
                    "text_blocks_count": len(ocr_result.get('text_blocks', []))
                })
                
                print(f"      âœ“ OCR: {len(ocr_result.get('text_blocks', []))} ä¸ªæ–‡æœ¬å—")
            except Exception as e:
                print(f"      âœ— å›¾ç‰‡å¤„ç†å¤±è´¥: {e}")
    
    # ==================== é˜¶æ®µ 3: VLM å¤„ç†ï¼ˆå¸¦æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼‰ ====================
    print(f"  ğŸ¤– é˜¶æ®µ3: VLM ç»¼åˆåˆ†æ...")
    
    # æ„å»º VLM æç¤ºï¼ˆåŒ…å«å·²æå–çš„æ–‡æœ¬ï¼‰
    vlm_context = {
        "extracted_text": extracted_text,
        "images": images,
        "image_ocr_results": image_ocr_results
    }
    
    # ç”Ÿæˆ VLM è¾“å…¥æç¤º
    vlm_prompt = f"""# å¹»ç¯ç‰‡ç¬¬ {slide_num} é¡µç»¼åˆåˆ†æ

## å·²æå–çš„æ–‡æœ¬å†…å®¹ï¼ˆé«˜å¯ä¿¡åº¦ï¼Œæ¥è‡ªPPTåŸå§‹æ•°æ®ï¼‰ï¼š

### æ ‡é¢˜
{extracted_text['title'] or 'æ— '}

### æ­£æ–‡å†…å®¹
"""
    for i, body in enumerate(extracted_text['body'], 1):
        vlm_prompt += f"{i}. {body}\n"
    
    if extracted_text['tables']:
        vlm_prompt += "\n### è¡¨æ ¼\n"
        for t_idx, table in enumerate(extracted_text['tables'], 1):
            vlm_prompt += f"è¡¨æ ¼ {t_idx}:\n"
            for row in table[:3]:
                vlm_prompt += f"  {' | '.join(row)}\n"
    
    if extracted_text['notes']:
        vlm_prompt += f"\n### å¤‡æ³¨\n{extracted_text['notes']}\n"
    
    vlm_prompt += f"""

## å›¾ç‰‡OCRç»“æœï¼ˆ{len(image_ocr_results)} å¼ å›¾ç‰‡ï¼‰ï¼š
"""
    for ocr_res in image_ocr_results:
        vlm_prompt += f"- å›¾ç‰‡ {ocr_res['image_id']}: {ocr_res['text_blocks_count']} ä¸ªæ–‡æœ¬å—\n"
    
    vlm_prompt += """

## VLM ä»»åŠ¡ï¼š
è¯·ç»¼åˆä¸Šè¿°ä¿¡æ¯ï¼Œç”Ÿæˆå®Œæ•´çš„é¡µé¢å†…å®¹æè¿°ï¼š
1. ç¡®è®¤å¹¶æ•´åˆå·²æå–çš„æ–‡æœ¬
2. è¡¥å……å›¾ç‰‡ä¸­çš„é¢å¤–ä¿¡æ¯ï¼ˆå›¾è¡¨ã€ç¤ºæ„å›¾ã€å›¾æ ‡ç­‰ï¼‰
3. è¯†åˆ«é¡µé¢çš„æ•´ä½“ç±»å‹å’Œä¸»é¢˜
4. æå–å…³é”®ä¿¡æ¯å’Œç»“æ„

è¿”å› JSON æ ¼å¼ã€‚
"""
    
    vlm_prompt_path = output_dir / f"page_{slide_num:03d}_vlm_prompt.txt"
    with open(vlm_prompt_path, 'w', encoding='utf-8') as f:
        f.write(vlm_prompt)
    
    # è¿™é‡Œå¯ä»¥è°ƒç”¨ VLMï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    # æš‚æ—¶ä¿å­˜æç¤ºå’Œä¸Šä¸‹æ–‡
    vlm_context_path = output_dir / f"page_{slide_num:03d}_vlm_context.json"
    with open(vlm_context_path, 'w', encoding='utf-8') as f:
        json.dump(vlm_context, f, ensure_ascii=False, indent=2)
    
    print(f"    âœ“ VLMä¸Šä¸‹æ–‡å’Œæç¤ºå·²ä¿å­˜")
    
    # ==================== æ„å»ºæœ€ç»ˆé¡µé¢æ•°æ® ====================
    # æ•´åˆæ‰€æœ‰æ–‡æœ¬
    all_text = []
    if extracted_text['title']:
        all_text.append(extracted_text['title'])
    all_text.extend(extracted_text['body'])
    if extracted_text['notes']:
        all_text.append(f"å¤‡æ³¨: {extracted_text['notes']}")
    
    # æ·»åŠ è¡¨æ ¼æ–‡æœ¬
    for table in extracted_text['tables']:
        for row in table:
            all_text.append(' | '.join(row))
    
    # ==================== é˜¶æ®µ 3.5: VLM æ™ºèƒ½æ–‡æœ¬ä¿®æ­£ï¼ˆæŒ‰éœ€è§¦å‘ï¼‰ ====================
    # æ·»åŠ å›¾ç‰‡OCRæ–‡æœ¬ï¼ˆåªä¿ç•™é«˜ç½®ä¿¡åº¦ï¼‰
    MIN_CONFIDENCE = 0.15
    vlm_model = None
    
    for ocr_res in image_ocr_results:
        try:
            with open(ocr_res['ocr_json'], 'r', encoding='utf-8') as f:
                ocr_data = json.load(f)
                # ä» text_blocks æå–é«˜ç½®ä¿¡åº¦æ–‡æœ¬
                if ocr_data.get('text_blocks'):
                    high_confidence_blocks = [
                        block for block in ocr_data['text_blocks']
                        if block.get('confidence', 0) >= MIN_CONFIDENCE and block.get('text')
                    ]
                    
                    # æ£€æµ‹æ˜¯å¦éœ€è¦ VLM ä¿®æ­£
                    all_blocks = ocr_data['text_blocks']
                    needs_refinement, reason, stats = detect_problem_content(all_blocks)
                    
                    if needs_refinement and high_confidence_blocks:
                        print(f"      ğŸ” è§¦å‘ VLM ä¿®æ­£ - {reason}")
                        print(f"         (å¹³å‡ç½®ä¿¡åº¦: {stats['avg_confidence']:.2f}, ä¹±ç ç‡: {stats['garbled_ratio']:.1%})")
                        
                        # å»¶è¿Ÿåˆå§‹åŒ– VLMï¼ˆåªæœ‰éœ€è¦æ—¶æ‰åŠ è½½ï¼‰
                        if vlm_model is None and HAS_VLM:
                            try:
                                vlm_model = VisionModel()
                                print(f"      âœ“ VLM æ¨¡å‹å·²åŠ è½½")
                            except Exception as e:
                                print(f"      âš ï¸  VLM åˆå§‹åŒ–å¤±è´¥: {e}")
                        
                        if vlm_model:
                            # è·å–åŸå§‹å›¾ç‰‡è·¯å¾„
                            img_id = ocr_res['image_id']
                            img_path = None
                            for img_info in images:
                                if img_info['id'] == img_id:
                                    img_path = img_info['path']
                                    break
                            
                            if img_path:
                                # åŸå§‹ OCR æ–‡æœ¬
                                original_text = ' '.join([block['text'] for block in high_confidence_blocks])
                                
                                # VLM ä¿®æ­£
                                context_hint = "æ–‡ä»¶åˆ—è¡¨" if stats.get('is_file_list') else ""
                                confidence_info = {
                                    'avg_confidence': stats['avg_confidence'],
                                    'garbled_ratio': stats['garbled_ratio'],
                                    'is_mindmap': stats.get('is_mindmap', False),
                                    'is_file_list': stats.get('is_file_list', False)
                                }
                                refined_text = refine_text_with_vlm(
                                    image_path=img_path,
                                    ocr_text=original_text,
                                    vlm_model=vlm_model,
                                    context_hint=context_hint,
                                    confidence_info=confidence_info
                                )
                                
                                if refined_text != original_text:
                                    print(f"      âœ“ VLM ä¿®æ­£å®Œæˆ ({len(original_text)} â†’ {len(refined_text)} å­—ç¬¦)")
                                    all_text.append(f"[å›¾ç‰‡ {ocr_res['image_id']}-VLMä¿®æ­£] {refined_text}")
                                else:
                                    all_text.append(f"[å›¾ç‰‡ {ocr_res['image_id']}-é«˜ç½®ä¿¡åº¦] " + original_text)
                            else:
                                # æ‰¾ä¸åˆ°å›¾ç‰‡è·¯å¾„ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
                                image_texts = [block['text'] for block in high_confidence_blocks]
                                all_text.append(f"[å›¾ç‰‡ {ocr_res['image_id']}-é«˜ç½®ä¿¡åº¦] " + ' '.join(image_texts))
                        else:
                            # VLM ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
                            image_texts = [block['text'] for block in high_confidence_blocks]
                            all_text.append(f"[å›¾ç‰‡ {ocr_res['image_id']}-é«˜ç½®ä¿¡åº¦] " + ' '.join(image_texts))
                    
                    elif high_confidence_blocks:
                        # è´¨é‡è‰¯å¥½ï¼Œç›´æ¥ä½¿ç”¨ OCR æ–‡æœ¬
                        image_texts = [block['text'] for block in high_confidence_blocks]
                        all_text.append(f"[å›¾ç‰‡ {ocr_res['image_id']}-é«˜ç½®ä¿¡åº¦] " + ' '.join(image_texts))
                    
                    # è®°å½•è¿‡æ»¤æƒ…å†µ
                    low_conf_count = len(ocr_data['text_blocks']) - len(high_confidence_blocks)
                    if low_conf_count > 0:
                        print(f"      â„¹ï¸  å›¾ç‰‡ {ocr_res['image_id']}: è¿‡æ»¤äº† {low_conf_count} ä¸ªä½ç½®ä¿¡åº¦æ–‡æœ¬å—")
        except Exception as e:
            print(f"      âš ï¸  æ— æ³•è¯»å–å›¾ç‰‡OCRç»“æœ: {e}")
    
    combined_text = '\n\n'.join(all_text)
    
    # è®¡ç®—æ•´ä½“OCRç½®ä¿¡åº¦ï¼ˆåŒ…æ‹¬å…¨å±€OCRå’Œå›¾ç‰‡OCRï¼‰
    all_confidences = []
    
    # ä»å…¨å±€OCRè·å–ç½®ä¿¡åº¦
    try:
        global_ocr_path = output_dir / f"page_{slide_num:03d}_global_ocr.json"
        if global_ocr_path.exists():
            with open(global_ocr_path, 'r', encoding='utf-8') as f:
                global_ocr = json.load(f)
                for block in global_ocr.get('text_blocks', []):
                    conf = block.get('confidence', 0)
                    if conf > 0:
                        all_confidences.append(conf)
    except Exception:
        pass
    
    # ä»å›¾ç‰‡OCRè·å–ç½®ä¿¡åº¦
    for ocr_res in image_ocr_results:
        try:
            with open(ocr_res['ocr_json'], 'r', encoding='utf-8') as f:
                ocr_data = json.load(f)
                for block in ocr_data.get('text_blocks', []):
                    conf = block.get('confidence', 0)
                    if conf > 0:
                        all_confidences.append(conf)
        except Exception:
            pass
    
    avg_ocr_confidence = sum(all_confidences) / len(all_confidences) if all_confidences else 0.0
    
    # ç»Ÿè®¡ä¿¡æ¯
    slide_data['statistics'] = {
        "total_text_blocks": len(all_text),
        "total_images": len(images),
        "has_title": bool(extracted_text['title']),
        "has_tables": len(extracted_text['tables']) > 0,
        "has_notes": bool(extracted_text['notes']),
        "avg_ocr_confidence": round(avg_ocr_confidence, 3)  # æ·»åŠ å¹³å‡ç½®ä¿¡åº¦
    }
    
    # Stage1 ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿ PDF çš„ç»“æ„ï¼‰
    slide_data['stage1_global'] = {
        "image": preview_image,
        "ocr_json": f"page_{slide_num:03d}_global_ocr.json", # æŒ‡å‘åŒ…å«åæ ‡çš„ OCR ç»“æœ
        "text_source": "direct_extraction_plus_ocr"
    }
    
    # Stage2 OCR å¯è§†åŒ–ä¿¡æ¯
    # æ³¨æ„ï¼švisualized_path å·²ç»åœ¨é˜¶æ®µ 1.5 ä¸­é€šè¿‡ visualize_extraction ç”Ÿæˆ
    # ä¸è¦è¦†ç›–å®ƒï¼Œå¦åˆ™ç»¿è‰² OCR æ¡†ä¼šä¸¢å¤±
    
    if not visualized_path.exists():
        # åªæœ‰åœ¨ç”Ÿæˆå¤±è´¥æ—¶æ‰é™çº§å¤„ç†
        if preview_path.exists():
            import shutil
            shutil.copy2(preview_path, visualized_path)
        elif images and image_ocr_results:
            # é™çº§ï¼šä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡çš„ OCR å¯è§†åŒ–
            first_vis = next((r['visualized'] for r in image_ocr_results if r['image_id'] == images[0]['id']), None)
            if first_vis and Path(first_vis).exists():
                import shutil
                shutil.copy2(first_vis, visualized_path)
    
    # Stage3 VLM ä¿¡æ¯
    slide_data['stage3_vlm'] = {
        "vlm_prompt": str(vlm_prompt_path.name),
        "vlm_context": str(vlm_context_path.name),
        "text_combined": combined_text
    }
    
    return slide_data, combined_text


def process_pptx(pptx_path, output_dir, ocr_engine='paddle'):
    """
    å®Œæ•´å¤„ç† PPTX æ–‡ä»¶
    ç”Ÿæˆä¸ adaptive_ocr_pipeline.py ç›¸åŒçš„è¾“å‡ºç»“æ„
    """
    print(f"ğŸš€ å¼€å§‹å¤„ç† PPTX: {pptx_path}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ”§ OCRå¼•æ“: {ocr_engine}")
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    pptx_path = Path(pptx_path)
    
    # ==================== æ­¥éª¤ 0: ä½¿ç”¨ LibreOffice è½¬æ¢ä¸º PDF å¹¶æ¸²æŸ“é¢„è§ˆå›¾ ====================
    print(f"\n{'='*70}")
    print(f"ğŸ“„ æ­¥éª¤ 0: ç”Ÿæˆé¡µé¢é¢„è§ˆå›¾ï¼ˆLibreOffice æ¸²æŸ“ï¼‰")
    print(f"{'='*70}")
    
    temp_pdf = output_dir / f"{pptx_path.stem}_temp.pdf"
    
    # è·å– LibreOffice å‘½ä»¤
    soffice_cmd = get_soffice_command()
    if not soffice_cmd:
        print("  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° LibreOffice (soffice)ï¼Œè·³è¿‡é¢„è§ˆå›¾ç”Ÿæˆ")
        print("  æç¤º: å®‰è£… LibreOffice å¹¶ç¡®ä¿ soffice å‘½ä»¤åœ¨ PATH ä¸­")
        print("  macOS: brew install --cask libreoffice")
        total_slides = None
    else:
        try:
            # è°ƒç”¨ LibreOffice è½¬æ¢ PPTX -> PDF
            print(f"  â³ è½¬æ¢ PPTX ä¸º PDF (ä½¿ç”¨: {soffice_cmd})...")
            subprocess.run([
                soffice_cmd,
                '--headless',
                '--convert-to', 'pdf',
                '--outdir', str(output_dir),
                str(pptx_path)
            ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
            # LibreOffice è¾“å‡ºçš„ PDF æ–‡ä»¶åä¸è¾“å…¥æ–‡ä»¶åç›¸åŒï¼ˆä»…æ‰©å±•åä¸åŒï¼‰
            generated_pdf = output_dir / f"{pptx_path.stem}.pdf"
            if generated_pdf.exists() and generated_pdf != temp_pdf:
                generated_pdf.rename(temp_pdf)
            
            print(f"  âœ“ PDF å·²ç”Ÿæˆ: {temp_pdf.name}")
            
            # ä½¿ç”¨ pdfplumber æ¸²æŸ“æ¯ä¸€é¡µä¸ºå›¾ç‰‡
            import pdfplumber
            import cv2
            import numpy as np
            
            with pdfplumber.open(temp_pdf) as pdf:
                total_slides = len(pdf.pages)
                print(f"  ğŸ“„ PDF é¡µæ•°: {total_slides}")
                
                for page_num, page in enumerate(pdf.pages, 1):
                    # æ¸²æŸ“ä¸ºé«˜è´¨é‡å›¾ç‰‡ï¼ˆ300 DPIï¼‰
                    img = page.to_image(resolution=300)
                    img_array = np.array(img.original)
                    
                    # ä¿å­˜ä¸º page_XXX_300dpi.pngï¼ˆä¸ PDF æµç¨‹å‘½åä¸€è‡´ï¼‰
                    preview_path = output_dir / f"page_{page_num:03d}_300dpi.png"
                    cv2.imwrite(str(preview_path), cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
                    
                    height, width = img_array.shape[:2]
                    print(f"  âœ“ ç¬¬ {page_num} é¡µ: {width}x{height}px -> {preview_path.name}")
            
            # åˆ é™¤ä¸´æ—¶ PDF æ–‡ä»¶
            temp_pdf.unlink()
            print(f"  âœ“ é¢„è§ˆå›¾ç”Ÿæˆå®Œæˆï¼Œä¸´æ—¶ PDF å·²æ¸…ç†")
            
        except Exception as e:
            print(f"  âš ï¸  é¢„è§ˆå›¾ç”Ÿæˆå¤±è´¥: {e}")
            total_slides = None
    
    # ==================== ç»§ç»­åŸæœ‰çš„å†…å®¹æå–æµç¨‹ ====================
    prs = Presentation(str(pptx_path))
    if total_slides is None:
        total_slides = len(prs.slides)
    
    print(f"\nğŸ“„ æ€»é¡µæ•°: {total_slides}")
    
    result = {
        "source_file": str(pptx_path),
        "file_type": "pptx",
        "total_pages": total_slides,
        "ocr_engine": ocr_engine,
        "pages": []
    }
    
    for slide_idx, slide in enumerate(prs.slides, 1):
        print(f"\n{'='*70}")
        print(f"ğŸ“„ å¤„ç†ç¬¬ {slide_idx}/{total_slides} é¡µ")
        print(f"{'='*70}")
        
        slide_data, combined_text = extract_slide_content(
            slide, slide_idx, output_dir, ocr_engine
        )
        
        result["pages"].append(slide_data)
        
        print(f"\nâœ… ç¬¬ {slide_idx} é¡µå®Œæˆ")
        print(f"  - æ–‡æœ¬å—: {slide_data['statistics']['total_text_blocks']}")
        print(f"  - å›¾ç‰‡: {slide_data['statistics']['total_images']}")
        print(f"  - å­—ç¬¦æ•°: {len(combined_text)}")
    
    # ä¿å­˜å®Œæ•´ç»“æœï¼ˆä¸ PDF çš„ complete_adaptive_ocr.json æ ¼å¼ä¸€è‡´ï¼‰
    complete_json = output_dir / "complete_adaptive_ocr.json"
    with open(complete_json, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆ complete_document.jsonï¼ˆç”¨äº ES ç´¢å¼•ï¼Œæ ‡å‡†æ ¼å¼ï¼‰
    pages_for_index = []
    for page in result['pages']:
        page_num = page['page_number']
        stage1 = page.get('stage1_global', {})
        stage3 = page.get('stage3_vlm', {})
        stats = page.get('statistics', {})
        
        # è·å–å›¾ç‰‡è·¯å¾„
        image_filename = stage1.get('image', f'page_{page_num:03d}_300dpi.png')
        image_path = output_dir / image_filename
        
        # è·å–æ–‡æœ¬å†…å®¹
        text_combined = stage3.get('text_combined', '')
        
        pages_for_index.append({
            'page_number': page_num,
            'image_path': str(image_path),
            'image_filename': image_filename,
            'content': {
                'full_text_cleaned': text_combined,
                'full_text_raw': text_combined,
                'key_fields': [],
                'tables': []
            },
            'ocr_data': {
                'text_blocks': []
            },
            'metadata': {
                'extraction_method': 'pptx_ocr_pipeline',
                'ocr_engine': ocr_engine,
                'avg_ocr_confidence': stats.get('avg_ocr_confidence', 0.0),
                'vlm_refined': False
            }
        })
    
    complete_document_path = output_dir / "complete_document.json"
    with open(complete_document_path, 'w', encoding='utf-8') as f:
        json.dump({'pages': pages_for_index}, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*70}")
    print(f"âœ… å¤„ç†å®Œæˆï¼")
    print(f"{'='*70}")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"  - æ€»é¡µæ•°: {total_slides}")
    print(f"  - è¾“å‡ºæ–‡ä»¶: {complete_json}")
    print(f"  - ç´¢å¼•æ–‡ä»¶: {complete_document_path}")
    print(f"  - è¾“å‡ºç›®å½•: {output_dir.absolute()}")
    
    return result


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="PPTX å®Œæ•´å¤„ç†ç®¡é“")
    parser.add_argument("input_file", help="è¾“å…¥ PPTX æ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", default=None, help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼špptx_outputï¼‰")
    parser.add_argument("--ocr-engine", choices=['easy', 'paddle', 'vision'], 
                       default='paddle', help="OCRå¼•æ“é€‰æ‹©")
    
    args = parser.parse_args()
    
    input_path = Path(args.input_file)
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        sys.exit(1)
    
    if args.output:
        output_dir = Path(args.output)
    else:
        # é»˜è®¤è¾“å‡ºç›®å½•ï¼šæ–‡ä»¶å_adaptive
        output_dir = Path(input_path.stem.replace(' ', '_') + "_adaptive")
    
    try:
        result = process_pptx(input_path, output_dir, args.ocr_engine)
        print(f"\nğŸ‰ æˆåŠŸï¼å¯ä»¥ä½¿ç”¨æ­¤è¾“å‡ºç›®å½•é›†æˆåˆ°ç³»ç»Ÿä¸­ã€‚")
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

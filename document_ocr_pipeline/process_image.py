#!/usr/bin/env python3
"""
å›¾ç‰‡æ–‡æ¡£æ™ºèƒ½ OCR å¤„ç†è„šæœ¬ï¼ˆæ”¯æŒ VLM ä¿®æ­£ï¼‰
æ”¯æŒï¼šPNG, JPG, JPEG ç­‰å›¾ç‰‡æ ¼å¼
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, Any, Tuple
import structlog

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.config import config

# åˆå§‹åŒ–æ—¥å¿—
logger = structlog.get_logger(__name__)

# å°è¯•å¯¼å…¥ VLM
HAS_VLM = False
try:
    from src.models import VisionModel
    HAS_VLM = True
except Exception as e:
    logger.warning(f"VLM not available: {e}")


def should_use_vlm_refinement(ocr_data: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦ VLM ä¿®æ­£
    
    Args:
        ocr_data: OCR åŸå§‹ç»“æœ
    
    Returns:
        (æ˜¯å¦éœ€è¦ä¿®æ­£, åŸå› , ç»Ÿè®¡ä¿¡æ¯)
    """
    text_blocks = ocr_data.get('text_blocks', [])
    
    if not text_blocks:
        return False, "æ— æ–‡æœ¬å†…å®¹", {}
    
    # ç»Ÿè®¡åˆ†æ
    confidences = [b.get('confidence', 0) for b in text_blocks if b.get('confidence', 0) > 0]
    avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
    
    # æ£€æµ‹ä¹±ç å­—ç¬¦
    all_text = ' '.join([b.get('text', '') for b in text_blocks])
    garbled_chars = sum(1 for c in all_text if ord(c) > 0x4E00 and c in 'ï¿½â–¡â–ªï¸â—†â– â—â—‹â—‡')
    garbled_ratio = garbled_chars / len(all_text) if all_text else 0.0
    
    # æ£€æµ‹æ–‡ä»¶åˆ—è¡¨æ¨¡å¼
    lines = [b.get('text', '').strip() for b in text_blocks if b.get('text', '').strip()]
    short_lines = sum(1 for line in lines if len(line) < 50)
    is_file_list = (
        short_lines > 5 and 
        short_lines / len(lines) > 0.6 if lines else False
    ) or any(ext in all_text.lower() for ext in ['.tar', '.dmg', '.pkg', '.gz', 'elasticsearch', 'docker'])
    
    # æ£€æµ‹å¤šè¡ŒçŸ­æ–‡æœ¬
    is_multi_short_lines = len(lines) >= 5 and short_lines / len(lines) > 0.7 if lines else False
    
    # æ£€æµ‹æ€ç»´å¯¼å›¾/å…³ç³»å›¾ï¼ˆæ ‘å½¢ç¬¦å·å¯†åº¦ï¼‰
    tree_symbols = sum(all_text.count(s) for s in ['â”œ', 'â””', 'â”‚', 'â”€â”€', 'â”€'])
    arrow_symbols = sum(all_text.count(s) for s in ['â†’', 'â†', 'â†“', 'â†‘', 'â‡’', 'â‡', 'â–¶', 'â—€'])
    is_mindmap = (tree_symbols > 5 or arrow_symbols > 3) and len(text_blocks) > 8
    
    stats = {
        'avg_confidence': avg_confidence,
        'garbled_ratio': garbled_ratio,
        'is_file_list': is_file_list,
        'is_multi_short_lines': is_multi_short_lines,
        'is_mindmap': is_mindmap,
        'tree_symbols_count': tree_symbols,
        'arrow_symbols_count': arrow_symbols,
        'total_blocks': len(text_blocks),
        'total_chars': len(all_text)
    }
    
    # å®½æ¾ä»‹å…¥ç­–ç•¥ï¼ˆ60-80% è¦†ç›–ç‡ï¼‰
    if avg_confidence < 0.8:  # 80% ä»¥ä¸‹å°±ä¿®æ­£
        return True, f"è¯†åˆ«è´¨é‡å¯æå‡ (ç½®ä¿¡åº¦ {avg_confidence:.2f})", stats
    elif garbled_ratio > 0.005:  # 0.5% ä¹±ç å³è§¦å‘
        return True, f"æ£€æµ‹åˆ°ä¹±ç  ({garbled_ratio:.1%})", stats
    elif stats.get('is_mindmap', False):  # æ€ç»´å¯¼å›¾
        return True, "æ£€æµ‹åˆ°æ€ç»´å¯¼å›¾/å…³ç³»å›¾", stats
    elif is_file_list or is_multi_short_lines:  # ç‰¹æ®Šæ ¼å¼
        return True, "æ£€æµ‹åˆ°åˆ—è¡¨ç»“æ„", stats
    
    return False, "è´¨é‡è‰¯å¥½", stats


def refine_text_with_vlm(
    image_path: Path,
    ocr_text: str,
    vlm_model,
    confidence_info: Dict[str, Any] = None
) -> str:
    """
    ä½¿ç”¨ VLM ä¿®æ­£ OCR æ–‡æœ¬
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        ocr_text: OCR åŸå§‹æ–‡æœ¬
        vlm_model: VisionModel å®ä¾‹
        confidence_info: ç½®ä¿¡åº¦ä¿¡æ¯
    
    Returns:
        ä¿®æ­£åçš„æ–‡æœ¬
    """
    if not HAS_VLM or not vlm_model:
        return ocr_text
    
    try:
        # æ„å»ºè´¨é‡æç¤ºä¿¡æ¯
        quality_note = ""
        context_hint = ""
        
        if confidence_info:
            avg_conf = confidence_info.get('avg_confidence', 0)
            garbled_ratio = confidence_info.get('garbled_ratio', 0)
            is_file_list = confidence_info.get('is_file_list', False)
            
            if avg_conf < 0.5:
                quality_note = f"\næ³¨æ„ï¼šOCR è¯†åˆ«è´¨é‡è¾ƒä½ï¼ˆå¹³å‡ç½®ä¿¡åº¦ {avg_conf:.1%}ï¼‰ï¼Œå¯èƒ½å­˜åœ¨è¾ƒå¤šé”™è¯¯ã€‚"
            if garbled_ratio > 0.03:
                quality_note += f"\næ³¨æ„ï¼šæ£€æµ‹åˆ° {garbled_ratio:.1%} çš„ä¹±ç å­—ç¬¦ï¼Œè¯·å‚è€ƒå›¾ç‰‡ä¿®æ­£ã€‚"
            if is_file_list:
                context_hint = "è¿™æ˜¯ä¸€ä¸ªæ–‡ä»¶åˆ—è¡¨"
        
        # æ„å»ºä¿®æ­£ç­–ç•¥æç¤º
        correction_level = ""
        content_type_hint = ""
        if confidence_info:
            avg_conf = confidence_info.get('avg_confidence', 0)
            is_mindmap = confidence_info.get('is_mindmap', False)
            is_file_list = confidence_info.get('is_file_list', False)
            
            if avg_conf < 0.5:
                correction_level = "ã€æ¿€è¿›ä¿®æ­£æ¨¡å¼ã€‘è¯†åˆ«è´¨é‡å¾ˆä½ï¼Œéœ€è¦å¤§å¹…ä¿®æ­£é”™åˆ«å­—å’Œç»“æ„æ ¼å¼"
            elif avg_conf < 0.7:
                correction_level = "ã€ä¸­ç­‰ä¿®æ­£æ¨¡å¼ã€‘é€‚åº¦ä¿®æ­£æ˜æ˜¾çš„é”™åˆ«å­—ï¼Œä¿ç•™å¤§éƒ¨åˆ†åŸæ–‡å’Œç»“æ„æ ¼å¼"
            else:
                correction_level = "ã€ä¿å®ˆä¿®æ­£æ¨¡å¼ã€‘ä»…ä¿®æ­£æ˜æ˜¾é”™è¯¯ï¼Œä¿ç•™æ ¼å¼å’Œè¾¹è·ï¼Œä¿ç•™åŸæœ‰ç»“æ„æ ¼å¼"
            
            # å†…å®¹ç±»å‹æç¤º
            if is_mindmap:
                content_type_hint = "\nâš ï¸ **è¿™æ˜¯æ€ç»´å¯¼å›¾/å…³ç³»å›¾**ï¼Œå¿…é¡»ä¿ç•™æ‰€æœ‰å±‚çº§å…³ç³»ã€åˆ†æ”¯ç»“æ„ã€ç®­å¤´æ–¹å‘ï¼"
            elif is_file_list:
                content_type_hint = "\nâš ï¸ **è¿™æ˜¯æ–‡ä»¶åˆ—è¡¨/ç›®å½•**ï¼Œå¿…é¡»ä¿ç•™å±‚çº§ç¼©è¿›å’Œç¬¦å·ï¼"
        
        prompt = f"""è¯·æ ¹æ®å›¾ç‰‡å’Œ OCR è¯†åˆ«ç»“æœï¼Œä¿®æ­£ä»¥ä¸‹æ–‡æœ¬ä¸­çš„é”™è¯¯ï¼š

OCR åŸå§‹ç»“æœï¼š
{ocr_text}

è¯†åˆ«è´¨é‡ä¿¡æ¯ï¼š
{quality_note}
{correction_level}
{content_type_hint}

ä¿®æ­£è¦æ±‚ï¼š
1. **é”™åˆ«å­—ä¿®æ­£**ï¼ˆå¿…é¡»å‚è€ƒå›¾ç‰‡ï¼‰ï¼š
   - å®¹å™¨ç›‘æ§/åº”ç”¨ç›‘æ§/æ•°æ®åº“ç›‘æ§ ç­‰ITæœ¯è¯­
   - å¸¸è§é”™è¯¯ï¼šå®¢å™¨â†’å®¹å™¨ã€ç”³é—´â†’ç©ºé—´ã€Vå¿—â†’æ—¥å¿—ã€ç¦ºâ†’åŸŸ
   - ä¸“æœ‰åè¯ï¼šCyberArkã€Kongã€API Gatewayã€CMDB

2. **æ ¼å¼ä¿ç•™**ï¼ˆç¦æ­¢ä¿®æ”¹ï¼‰ï¼š
   - æ ‘å½¢ç¬¦å·ï¼šâ”œ â”‚ â”” â”€â”€ 
   - ç®­å¤´ç¬¦å·ï¼šâ†’ â† â†“ â†‘ â‡’ â–¶
   - ç¼©è¿›å±‚çº§ï¼šå¿…é¡»ä¸åŸæ–‡ä¸€è‡´
   - æ¢è¡Œä½ç½®ï¼šä¿æŒåŸæœ‰å¸ƒå±€

3. **ç»“æ„ä¿®å¤**ï¼ˆæ€ç»´å¯¼å›¾/å…³ç³»å›¾é‡ç‚¹ï¼‰ï¼š
   - **è¡¥å……ä¸¢å¤±çš„å±‚çº§ç¬¦å·**ï¼ˆ/, -, |, â”œ, â””ï¼‰
   - **æ¢å¤çˆ¶å­å…³ç³»**ï¼ˆå¦‚ A â†’ B â†’ C çš„æµå‘ï¼‰
   - **ä¿æŒåˆ†æ”¯ç»“æ„**ï¼ˆå¤šä¸ªå­èŠ‚ç‚¹å¿…é¡»å…¨éƒ¨å±•ç¤ºï¼‰
   - åˆå¹¶è¢«é”™è¯¯åˆ†å‰²çš„è¯è¯­

4. **ç¦æ­¢è¡Œä¸º**ï¼š
   - ä¸è¦æ·»åŠ åŸå›¾ä¸­æ²¡æœ‰çš„å†…å®¹
   - ä¸è¦æ”¹å˜èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å…³ç³»
   - ä¸è¦åˆå¹¶åº”è¯¥åˆ†å¼€çš„åˆ†æ”¯
   - ä¸è¦åˆ é™¤çœ‹ä¼¼é‡å¤ä½†å®é™…å­˜åœ¨çš„å†…å®¹

{f'æç¤ºï¼š{context_hint}' if context_hint else ''}

è¯·ç›´æ¥è¿”å›ä¿®æ­£åçš„æ–‡æœ¬å†…å®¹ï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šã€‚"""

        logger.info("ğŸ¤– è°ƒç”¨ VLM ä¿®æ­£æ–‡æœ¬...",
                   image=str(image_path.name),
                   ocr_length=len(ocr_text),
                   avg_confidence=confidence_info.get('avg_confidence', 0) if confidence_info else 0)
        
        response = vlm_model.extract_text_from_image(str(image_path), prompt)
        refined_text = response.get('text', ocr_text)
        
        # åŸºæœ¬éªŒè¯ï¼šé˜²æ­¢ VLM å¹»è§‰æˆ–æˆªæ–­
        if len(refined_text) < len(ocr_text) * 0.3 or len(refined_text) > len(ocr_text) * 5:
            logger.warning("âš ï¸  VLM ä¿®æ­£ç»“æœé•¿åº¦å¼‚å¸¸ï¼Œä½¿ç”¨åŸå§‹ OCR",
                          original_len=len(ocr_text),
                          refined_len=len(refined_text))
            return ocr_text
        
        logger.info("âœ… VLM ä¿®æ­£å®Œæˆ",
                   original_len=len(ocr_text),
                   refined_len=len(refined_text),
                   change_ratio=f"{(len(refined_text)/len(ocr_text)-1)*100:+.1f}%")
        
        return refined_text
        
    except Exception as e:
        logger.error(f"âŒ VLM ä¿®æ­£å¤±è´¥: {e}", image_path=str(image_path))
        return ocr_text


def process_image(
    image_path: Path,
    output_dir: Path,
    ocr_engine: str = 'vision'
) -> Dict[str, Any]:
    """
    å¤„ç†å•ä¸ªå›¾ç‰‡æ–‡ä»¶
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        ocr_engine: OCR å¼•æ“
    
    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    from document_ocr_pipeline.extract_document import DocumentExtractor
    from document_ocr_pipeline.visualize_extraction import visualize_extraction
    
    logger.info("=" * 80)
    logger.info("ğŸ–¼ï¸  å¼€å§‹å¤„ç†å›¾ç‰‡æ–‡æ¡£", image=image_path.name, ocr_engine=ocr_engine)
    logger.info("=" * 80)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ===== é˜¶æ®µ 1: å…¨å±€ OCR =====
    logger.info("ğŸ“ é˜¶æ®µ 1: å…¨å±€ OCR è¯†åˆ«")
    
    extractor = DocumentExtractor(ocr_engine=ocr_engine)
    ocr_json_path = output_dir / "image_ocr.json"
    
    logger.info(f"  ğŸ” ä½¿ç”¨ {ocr_engine.upper()} å¼•æ“...")
    ocr_result = extractor.extract_from_image(str(image_path))
    
    with open(ocr_json_path, 'w', encoding='utf-8') as f:
        json.dump(ocr_result, f, ensure_ascii=False, indent=2)
    
    text_blocks = ocr_result.get('text_blocks', [])
    logger.info(f"  âœ… è¯†åˆ«åˆ° {len(text_blocks)} ä¸ªæ–‡æœ¬å—")
    
    # æå–åŸå§‹æ–‡æœ¬
    original_text = ocr_result.get('text', '')
    if not original_text and text_blocks:
        original_text = '\n'.join([b.get('text', '') for b in text_blocks if b.get('text')])
    
    logger.info(f"  ğŸ“ æå–æ–‡æœ¬: {len(original_text)} å­—ç¬¦")
    
    # ===== é˜¶æ®µ 2: VLM æ™ºèƒ½ä¿®æ­£ =====
    logger.info("ğŸ“ é˜¶æ®µ 2: VLM æ™ºèƒ½ä¿®æ­£åˆ¤æ–­")
    
    need_vlm, reason, stats = should_use_vlm_refinement(ocr_result)
    
    logger.info(f"  ğŸ¯ è´¨é‡åˆ†æ:", **stats)
    logger.info(f"  {'âœ…' if need_vlm else 'âŒ'} VLM ä¿®æ­£: {reason}")
    
    final_text = original_text
    vlm_refined = False
    
    if need_vlm and HAS_VLM:
        try:
            vlm_config = config.vision_config
            if vlm_config.get('enabled', False):
                vlm_model = VisionModel(vlm_config)
                
                confidence_info = {
                    'avg_confidence': stats['avg_confidence'],
                    'garbled_ratio': stats['garbled_ratio'],
                    'is_file_list': stats.get('is_file_list', False),
                    'is_mindmap': stats.get('is_mindmap', False)
                }
                
                final_text = refine_text_with_vlm(
                    image_path=image_path,
                    ocr_text=original_text,
                    vlm_model=vlm_model,
                    confidence_info=confidence_info
                )
                
                if final_text != original_text:
                    vlm_refined = True
                    logger.info("  âœ… VLM ä¿®æ­£å®Œæˆ",
                               original_len=len(original_text),
                               refined_len=len(final_text))
            else:
                logger.info("  âš ï¸  VLM æœªå¯ç”¨ï¼Œè·³è¿‡ä¿®æ­£")
        except Exception as e:
            logger.error(f"  âŒ VLM ä¿®æ­£å¤±è´¥: {e}")
            final_text = original_text
    
    # ===== é˜¶æ®µ 3: ç”Ÿæˆå¯è§†åŒ– =====
    logger.info("ğŸ“ é˜¶æ®µ 3: ç”Ÿæˆ OCR å¯è§†åŒ–")
    
    visualized_path = output_dir / "image_visualized.png"
    visualize_extraction(str(image_path), str(ocr_json_path), str(visualized_path))
    logger.info(f"  âœ… å¯è§†åŒ–å›¾ç‰‡: {visualized_path.name}")
    
    # ===== é˜¶æ®µ 4: ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯ =====
    logger.info("ğŸ“ é˜¶æ®µ 4: ç”Ÿæˆå…ƒæ•°æ®")
    
    # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
    confidences = [b.get('confidence', 0) for b in text_blocks if b.get('confidence', 0) > 0]
    avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
    
    statistics = {
        "total_text_blocks": len(text_blocks),
        "avg_ocr_confidence": round(avg_confidence, 3),
        "vlm_refined": vlm_refined,
        "ocr_engine": ocr_engine
    }
    
    # ===== é˜¶æ®µ 5: æ„å»ºæœ€ç»ˆæ–‡æ¡£ =====
    logger.info("ğŸ“ é˜¶æ®µ 5: æ„å»ºæœ€ç»ˆæ–‡æ¡£")
    
    # å¤åˆ¶åŸå§‹å›¾ç‰‡ä½œä¸ºé¢„è§ˆ (ç»Ÿä¸€å‘½åä¸º page_001_300dpi.png)
    import shutil
    preview_path = output_dir / "page_001_300dpi.png"
    shutil.copy(image_path, preview_path)
    
    # æ„å»ºé¡µé¢æ•°æ®
    page_data = {
        "page_number": 1,
        "statistics": statistics,
        "stage1_global": {
            "image": preview_path.name,
            "ocr_json": ocr_json_path.name,
            "visualized": visualized_path.name,
            "text_source": "ocr" + ("_vlm_refined" if vlm_refined else "")
        },
        "stage2_vlm": {
            "text_combined": final_text,
            "vlm_refined": vlm_refined,
            "original_text_length": len(original_text),
            "final_text_length": len(final_text)
        } if vlm_refined else None
    }
    
    complete_doc = {
        "source_file": str(image_path),
        "file_type": image_path.suffix.lower().lstrip('.'),
        "total_pages": 1,
        "ocr_engine": ocr_engine,
        "pages": [page_data]
    }
    
    # ä¿å­˜å®Œæ•´æ–‡æ¡£ JSON
    complete_json_path = output_dir / "complete_adaptive_ocr.json"
    with open(complete_json_path, 'w', encoding='utf-8') as f:
        json.dump(complete_doc, f, ensure_ascii=False, indent=2)
    
    logger.info(f"  âœ… å…ƒæ•°æ®: {complete_json_path.name}")
    
    # ä¿å­˜å¯æœç´¢æ–‡æœ¬ï¼ˆç”¨äº ES ç´¢å¼•ï¼‰
    pages_for_index = [{
        'page_number': 1,
        'text': final_text,
        'text_blocks': text_blocks,
        'extraction_method': 'ocr_vlm_refined' if vlm_refined else 'ocr',
        'ocr_engine': ocr_engine,
        'avg_ocr_confidence': avg_confidence
    }]
    
    complete_document_path = output_dir / "complete_document.json"
    with open(complete_document_path, 'w', encoding='utf-8') as f:
        json.dump({'pages': pages_for_index}, f, ensure_ascii=False, indent=2)
    
    logger.info(f"  âœ… ç´¢å¼•æ–‡æ¡£: {complete_document_path.name}")
    
    logger.info("=" * 80)
    logger.info("ğŸ‰ å›¾ç‰‡å¤„ç†å®Œæˆ!")
    logger.info(f"  ğŸ“Š ç»Ÿè®¡: {len(text_blocks)} ä¸ªæ–‡æœ¬å—, å¹³å‡ç½®ä¿¡åº¦ {avg_confidence:.1%}")
    logger.info(f"  {'âœ…' if vlm_refined else 'âŒ'} VLM ä¿®æ­£: {reason}")
    logger.info("=" * 80)
    
    return {
        "status": "success",
        "output_dir": str(output_dir),
        "ocr_json": str(ocr_json_path),
        "visualized": str(visualized_path),
        "complete_json": str(complete_json_path),
        "text_length": len(final_text),
        "text_blocks_count": len(text_blocks),
        "avg_confidence": avg_confidence,
        "vlm_refined": vlm_refined
    }


def main():
    parser = argparse.ArgumentParser(description='å›¾ç‰‡æ–‡æ¡£æ™ºèƒ½ OCR å¤„ç†ï¼ˆæ”¯æŒ VLM ä¿®æ­£ï¼‰')
    parser.add_argument('image_path', type=str, help='å›¾ç‰‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--ocr-engine', type=str, default='vision',
                       choices=['vision', 'paddle', 'easy'],
                       help='OCR å¼•æ“é€‰æ‹© (é»˜è®¤: vision)')
    parser.add_argument('-o', '--output-dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šå›¾ç‰‡å_processedï¼‰')
    
    args = parser.parse_args()
    
    image_path = Path(args.image_path)
    if not image_path.exists():
        print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
        sys.exit(1)
    
    # ç¡®å®šè¾“å‡ºç›®å½•
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        output_dir = image_path.parent / f"{image_path.stem}_processed"
    
    try:
        result = process_image(image_path, output_dir, args.ocr_engine)
        print(f"\nâœ… å¤„ç†æˆåŠŸ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {result['output_dir']}")
        print(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {result['text_length']} å­—ç¬¦")
        print(f"ğŸ“Š æ–‡æœ¬å—æ•°: {result['text_blocks_count']} ä¸ª")
        print(f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {result['avg_confidence']:.1%}")
        print(f"ğŸ¤– VLM ä¿®æ­£: {'âœ… å·²åº”ç”¨' if result['vlm_refined'] else 'âŒ æœªä½¿ç”¨'}")
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()


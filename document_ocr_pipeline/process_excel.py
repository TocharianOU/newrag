#!/usr/bin/env python3
"""
Excel (.xlsx) æ··åˆå¤„ç†ç®¡é“
ç­–ç•¥ï¼š
1. è§†è§‰å±‚ (Preview)ï¼šLibreOffice -> PDF -> é¢„è§ˆå›¾ (æ‰€è§å³æ‰€å¾—)
2. æ•°æ®å±‚ (RAG/Search)ï¼šPandas -> Markdown è¡¨æ ¼ (ç”¨äºæ–‡æœ¬é—®ç­”)
3. ç»“æ„åŒ–å±‚ (Precise)ï¼šPandas -> Key-Value List (ç”¨äº ES ç²¾å‡†è¿‡æ»¤)
"""

import sys
import json
import argparse
from pathlib import Path
import subprocess
import pandas as pd
import pdfplumber
import cv2
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from document_ocr_pipeline.extract_document import DocumentExtractor
from document_ocr_pipeline.visualize_extraction import visualize_extraction

def df_to_markdown(df):
    """å°† DataFrame è½¬æ¢ä¸º Markdown è¡¨æ ¼"""
    # å¤„ç†ç©ºå€¼
    df = df.fillna("")
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    df = df.astype(str)
    # æ›¿æ¢æ¢è¡Œç¬¦
    df = df.replace(r'\n', ' ', regex=True)
    return df.to_markdown(index=False)

def df_to_structured_kv(df, sheet_name):
    """å°† DataFrame è½¬æ¢ä¸º ES Nested Key-Value åˆ—è¡¨"""
    kv_list = []
    df = df.fillna("")
    
    # éå†æ¯è¡Œ
    for _, row in df.iterrows():
        for col_name, val in row.items():
            # è·³è¿‡ç©ºå€¼æˆ–ç©ºåˆ—å
            if not str(col_name).strip() or val == "":
                continue
                
            kv_list.append({
                "key": str(col_name).strip(),
                "value": str(val).strip(),
                "sheet_name": sheet_name
            })
    return kv_list

def process_excel(excel_path, output_dir, ocr_engine='paddle'):
    """
    å®Œæ•´å¤„ç† Excel æ–‡ä»¶
    """
    print(f"ğŸš€ å¼€å§‹å¤„ç† Excel: {excel_path}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    excel_path = Path(excel_path)
    
    # ==================== æ­¥éª¤ 1: ä½¿ç”¨ Pandas æå–é«˜ç²¾åº¦æ•°æ® ====================
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æ­¥éª¤ 1: Pandas æ·±åº¦æ•°æ®æå– (Markdown + Structured KV)")
    print(f"{'='*70}")
    
    sheets_data = {} # å­˜å‚¨æ¯ä¸ª Sheet çš„ Markdown å’Œ KV
    all_structured_kv = [] # æ±‡æ€»æ‰€æœ‰ KV
    
    try:
        # è¯»å–æ‰€æœ‰ Sheets
        # header=0 é»˜è®¤ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´ï¼Œè¿™å¯¹å¤§å¤šæ•°æŠ¥è¡¨é€‚ç”¨
        # å¯¹äºå¤æ‚å¤šå±‚è¡¨å¤´ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå–ç¬¬ä¸€è¡Œéç©ºè¡Œ
        excel_file = pd.ExcelFile(excel_path)
        
        for sheet_name in excel_file.sheet_names:
            print(f"  ğŸ“‘ å¤„ç† Sheet: {sheet_name}")
            df = excel_file.parse(sheet_name)
            
            # 1. ç”Ÿæˆ Markdown (ç”¨äº Text RAG)
            if not df.empty:
                md_table = df_to_markdown(df)
                
                # 2. ç”Ÿæˆ Structured KV (ç”¨äº ES ç²¾å‡†æœç´¢)
                kv_data = df_to_structured_kv(df, sheet_name)
                
                sheets_data[sheet_name] = {
                    "markdown": md_table,
                    "kv_data": kv_data,
                    "row_count": len(df)
                }
                all_structured_kv.extend(kv_data)
                print(f"    âœ“ æå– {len(df)} è¡Œæ•°æ®, {len(kv_data)} ä¸ªKVå¯¹")
            else:
                print("    âš ï¸  ç©º Sheetï¼Œè·³è¿‡")
                
    except Exception as e:
        print(f"  âŒ Pandas è¯»å–å¤±è´¥: {e}")
        return None

    # ==================== æ­¥éª¤ 2: LibreOffice è½¬æ¢ PDF (è·å–è§†è§‰å¸ƒå±€) ====================
    print(f"\n{'='*70}")
    print(f"ğŸ“„ æ­¥éª¤ 2: ç”Ÿæˆé¢„è§ˆå›¾ (LibreOffice)")
    print(f"{'='*70}")
    
    temp_pdf = output_dir / f"{excel_path.stem}_temp.pdf"
    
    try:
        print(f"  â³ è½¬æ¢ Excel ä¸º PDF...")
        # Excel è½¬ PDF å¯èƒ½éœ€è¦è°ƒæ•´çº¸å¼ æ–¹å‘ï¼Œä½† LibreOffice é»˜è®¤ä¼šè‡ªåŠ¨é€‚åº”
        subprocess.run([
            '/Applications/LibreOffice.app/Contents/MacOS/soffice',
            '--headless',
            '--convert-to', 'pdf',
            '--outdir', str(output_dir),
            str(excel_path)
        ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        generated_pdf = output_dir / f"{excel_path.stem}.pdf"
        if generated_pdf.exists() and generated_pdf != temp_pdf:
            generated_pdf.rename(temp_pdf)
            
        print(f"  âœ“ PDF å·²ç”Ÿæˆ: {temp_pdf.name}")
        
    except Exception as e:
        print(f"  âŒ é¢„è§ˆå›¾ç”Ÿæˆå¤±è´¥: {e}")
        # å¦‚æœæ²¡æœ‰é¢„è§ˆå›¾ï¼Œæˆ‘ä»¬è‡³å°‘è¿˜æœ‰ Pandas æ•°æ®ï¼Œä¸åº”è¯¥å®Œå…¨ä¸­æ–­
        temp_pdf = None

    # ==================== æ­¥éª¤ 3: é€é¡µå¤„ç† PDF å¹¶åˆå¹¶ Pandas æ•°æ® ====================
    # ç­–ç•¥ï¼š
    # 1. ä¼˜å…ˆä½¿ç”¨ PDF æå–çš„æ–‡æœ¬ä½œä¸º"ç‰©ç†é¡µé¢"çš„å†…å®¹ã€‚
    # 2. å°† Pandas æå–çš„ Markdown è¡¨æ ¼é™„åœ¨ç¬¬ä¸€é¡µ (æˆ–è€…æ ¹æ® Sheet é¡ºåºé™„åœ¨ä¸åŒé¡µï¼Œä½†éš¾ä»¥ç²¾ç¡®å¯¹åº”)ã€‚
    #    ä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰ Sheet çš„ Markdown æ±‡æ€»åˆ° Page 1 çš„ text ä¸­ï¼Œ
    #    å¹¶å°†å…¶ä½™é¡µé¢çš„ text è®¾ä¸º PDF æå–å†…å®¹ (é€šå¸¸æ˜¯åˆ†é¡µåçš„è¡¨æ ¼ç‰‡æ®µ)ã€‚
    # 3. æœ€é‡è¦çš„æ˜¯ï¼šå°† structured_content æ”¾å…¥ metadataï¼Œä¾› ES å…¨å±€ç´¢å¼•ã€‚
    
    pages_data = []
    total_pages = 0
    
    if temp_pdf and temp_pdf.exists():
        with pdfplumber.open(temp_pdf) as pdf:
            total_pages = len(pdf.pages)
            print(f"  ğŸ“š æ€»é¡µæ•°: {total_pages}")
            
            for page_num, page in enumerate(pdf.pages, 1):
                print(f"\nå¤„ç†ç¬¬ {page_num}/{total_pages} é¡µ...")
                
                # 3.1 ç”Ÿæˆé¢„è§ˆå›¾
                img = page.to_image(resolution=300)
                preview_image = f"page_{page_num:03d}_300dpi.png"
                preview_path = output_dir / preview_image
                cv2.imwrite(str(preview_path), cv2.cvtColor(np.array(img.original), cv2.COLOR_RGB2BGR))
                print(f"  ğŸ–¼ï¸  é¢„è§ˆå›¾: {preview_image}")
                
                # 3.2 æå– PDF æ–‡æœ¬ (ä½œä¸ºä¸Šä¸‹æ–‡)
                pdf_text = page.extract_text() or ""
                
                # 3.3 ç»„åˆæœ€ç»ˆæ–‡æœ¬
                final_text = pdf_text
                
                # ç¬¬ä¸€é¡µç‰¹æƒï¼šé™„ä¸Šæ‰€æœ‰ Sheets çš„ Markdown é«˜ç²¾åº¦è¡¨æ ¼
                if page_num == 1:
                    final_text += "\n\nã€å®Œæ•´ç»“æ„åŒ–æ•°æ® (Pandas Source)ã€‘\n"
                    for sheet_name, data in sheets_data.items():
                        final_text += f"\n### Sheet: {sheet_name}\n"
                        final_text += data["markdown"]
                        final_text += "\n"
                
                # 3.4 æ„å»º Page Data
                pages_data.append({
                    "page_number": page_num,
                    "image_filename": preview_image,
                    "image_path": str(preview_path),
                    "content": {
                        "full_text_cleaned": final_text,
                        "full_text_raw": final_text
                    },
                    "ocr_data": {"text_blocks": []}, # æš‚ä¸å¯ç”¨ OCR ä»¥èŠ‚çœæ—¶é—´ï¼Œé™¤ééœ€è¦
                    "metadata": {
                        "extraction_method": "excel_hybrid_pandas_pdf",
                        "avg_ocr_confidence": 1.0
                    }
                })
    else:
        # å¦‚æœ PDF ç”Ÿæˆå¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªè™šæ‹Ÿé¡µé¢å­˜æ”¾æ•°æ®
        print("  âš ï¸  PDFç”Ÿæˆå¤±è´¥ï¼Œåˆ›å»ºçº¯æ•°æ®è™šæ‹Ÿé¡µ")
        final_text = "\n\nã€å®Œæ•´ç»“æ„åŒ–æ•°æ® (Pandas Source)ã€‘\n"
        for sheet_name, data in sheets_data.items():
            final_text += f"\n### Sheet: {sheet_name}\n"
            final_text += data["markdown"] + "\n"
            
        pages_data.append({
            "page_number": 1,
            "image_filename": "placeholder.png",
            "content": {
                "full_text_cleaned": final_text,
                "full_text_raw": final_text
            },
            "metadata": {"extraction_method": "excel_pandas_only"}
        })
        total_pages = 1

    # ==================== æ­¥éª¤ 4: è¾“å‡º JSON (åŒ…å« structured_content) ====================
    
    # è¿™é‡Œçš„ trick æ˜¯ï¼šES ç´¢å¼•æ—¶ï¼Œé€šå¸¸æ˜¯æŠŠ pages_for_index é‡Œçš„æ¯ä¸€é¡¹ä½œä¸ºä¸€ä¸ª Documentã€‚
    # æˆ‘ä»¬éœ€è¦æŠŠ structured_content æ”¾åˆ°æ¯ä¸€é¡µçš„ metadata é‡Œå—ï¼Ÿ
    # ä¸ï¼Œè¿™ä¼šé€ æˆå†—ä½™ã€‚ä½†ä¸ºäº†æœç´¢æ–¹ä¾¿ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›æœåˆ°"ä»»æ„ä¸€é¡µ"ã€‚
    # æœ€ä½³å®è·µï¼šå°† structured_content æ”¾å…¥ metadataï¼Œè¿™æ ·æ¯ä¸€é¡µéƒ½å¸¦æœ‰è¿™ä¸ª KV å±æ€§ï¼Œ
    # ç”¨æˆ·æœ "name: Luke" æ—¶ï¼Œä¼šè¿”å›æ‰€æœ‰é¡µé¢ï¼ˆæˆ–ç¬¬ä¸€é¡µï¼‰ã€‚
    
    # ä¸ºäº†é¿å…å†—ä½™å¤ªé‡ï¼Œæˆ‘ä»¬åªåœ¨ç¬¬ä¸€é¡µæ”¾å…¥ structured_contentï¼Ÿ
    # æˆ–è€…è®© vector_store.py å¤„ç†ã€‚
    # è¿™é‡Œæˆ‘ä»¬å…ˆæŠŠ structured_content æ”¾åœ¨é¡¶å±‚ï¼Œç”± document_processor å†³å®šå¦‚ä½•åˆ†é…ã€‚
    
    output_data = {
        "pages": pages_data,
        "structured_content": all_structured_kv # é¡¶å±‚æºå¸¦ KV æ•°æ®
    }
    
    complete_doc_path = output_dir / "complete_document.json"
    with open(complete_doc_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
        
    print(f"\n{'='*70}")
    print(f"âœ… Excel å¤„ç†å®Œæˆ")
    print(f"ğŸ“Š ç»Ÿè®¡: {total_pages} é¡µ, {len(all_structured_kv)} ä¸ªç»“æ„åŒ–KVå¯¹")
    print(f"ğŸ“‚ è¾“å‡º: {complete_doc_path}")
    print(f"{'='*70}")
    
    return output_data

def main():
    parser = argparse.ArgumentParser(description='Process Excel file')
    parser.add_argument('excel_file', help='Path to XLSX file')
    parser.add_argument('-o', '--output', help='Output directory', default=None)
    
    args = parser.parse_args()
    excel_path = Path(args.excel_file)
    
    if args.output:
        output_dir = Path(args.output)
    else:
        output_dir = Path(f"{excel_path.stem}_excel_processed")
        
    try:
        process_excel(excel_path, output_dir)
        return 0
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == '__main__':
    sys.exit(main())



#!/usr/bin/env python3
"""
DOCX å®Œæ•´å¤„ç†ç®¡é“ (åŸºäº PDFPlumber é‡æ„ç‰ˆ)
æ–¹æ¡ˆ Bï¼šDOCX -> PDF -> PDFPlumber é€é¡µæå–
ä¼˜åŠ¿ï¼š
1. ç²¾ç¡®çš„ç‰©ç†åˆ†é¡µ (Page-aware)
2. è¡¨æ ¼å®šä½å‡†ç¡® (Table-aware)
3. Markdown æ ¼å¼è¾“å‡º (LLM-friendly)
4. ç»Ÿä¸€çš„ PDF å¤„ç†é€»è¾‘
"""

import sys
import json
import argparse
from pathlib import Path
import io
import subprocess
import shutil

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from document_ocr_pipeline.extract_document import DocumentExtractor
from document_ocr_pipeline.visualize_extraction import visualize_extraction

def extract_table_to_markdown(table):
    """
    å°† pdfplumber æå–çš„è¡¨æ ¼è½¬æ¢ä¸º Markdown æ ¼å¼
    table: list of lists of strings
    """
    if not table:
        return ""
        
    # æ¸…ç†å•å…ƒæ ¼æ•°æ®ï¼šå»é™¤ Noneï¼Œå»é™¤é¦–å°¾ç©ºæ ¼ï¼Œå¤„ç†æ¢è¡Œç¬¦
    cleaned_table = []
    for row in table:
        cleaned_row = []
        for cell in row:
            if cell is None:
                cleaned_cell = ""
            else:
                # æ›¿æ¢æ¢è¡Œç¬¦ä¸ºç©ºæ ¼ï¼Œé¿å…ç ´å Markdown è¡¨æ ¼ç»“æ„
                cleaned_cell = str(cell).strip().replace('\n', ' ')
            cleaned_row.append(cleaned_cell)
        cleaned_table.append(cleaned_row)
        
    if not cleaned_table:
        return ""
        
    markdown_lines = []
    
    # 1. è¡¨å¤´
    headers = cleaned_table[0]
    markdown_lines.append("| " + " | ".join(headers) + " |")
    
    # 2. åˆ†éš”çº¿
    markdown_lines.append("| " + " | ".join(["---"] * len(headers)) + " |")
    
    # 3. æ•°æ®è¡Œ
    for row in cleaned_table[1:]:
        # ç¡®ä¿è¡Œé•¿åº¦ä¸€è‡´
        padded_row = row + [""] * (len(headers) - len(row))
        markdown_lines.append("| " + " | ".join(padded_row[:len(headers)]) + " |")
        
    return "\n".join(markdown_lines)

def process_docx(docx_path, output_dir, ocr_engine='paddle'):
    """
    å®Œæ•´å¤„ç† DOCX æ–‡ä»¶ (é€šè¿‡ PDF ä¸­è½¬)
    """
    print(f"ğŸš€ å¼€å§‹å¤„ç† DOCX (æ–¹æ¡ˆB: PDFä¸­è½¬): {docx_path}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ”§ OCRå¼•æ“: {ocr_engine}")
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    docx_path = Path(docx_path)
    
    # ==================== æ­¥éª¤ 1: LibreOffice è½¬æ¢ DOCX -> PDF ====================
    print(f"\n{'='*70}")
    print(f"ğŸ“„ æ­¥éª¤ 1: è½¬æ¢ä¸º PDF (è·å–ç²¾å‡†å¸ƒå±€)")
    print(f"{'='*70}")
    
    temp_pdf = output_dir / f"{docx_path.stem}_temp.pdf"
    
    try:
        print(f"  â³ è½¬æ¢ DOCX ä¸º PDF...")
        subprocess.run([
            '/Applications/LibreOffice.app/Contents/MacOS/soffice',
            '--headless',
            '--convert-to', 'pdf',
            '--outdir', str(output_dir),
            str(docx_path)
        ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        # LibreOffice è¾“å‡ºçš„æ–‡ä»¶åå¤„ç†
        generated_pdf = output_dir / f"{docx_path.stem}.pdf"
        if generated_pdf.exists() and generated_pdf != temp_pdf:
            generated_pdf.rename(temp_pdf)
        
        print(f"  âœ“ PDF å·²ç”Ÿæˆ: {temp_pdf.name}")
        
    except FileNotFoundError:
        print("  âŒ é”™è¯¯: æœªæ‰¾åˆ° LibreOfficeï¼Œæ— æ³•è¿›è¡Œè½¬æ¢")
        print("  è¯·å®‰è£…: brew install --cask libreoffice")
        return None
    except Exception as e:
        print(f"  âŒ è½¬æ¢å¤±è´¥: {e}")
        return None

    # ==================== æ­¥éª¤ 2: åˆå§‹åŒ– OCR å¼•æ“ ====================
    print(f"\n{'='*70}")
    print(f"ğŸ“„ æ­¥éª¤ 2: åˆå§‹åŒ–å¼•æ“")
    print(f"{'='*70}")
    
    ocr_extractor = DocumentExtractor(use_layout_detection=False, ocr_engine=ocr_engine)
    print(f"  âœ“ OCR å¼•æ“å°±ç»ª: {ocr_engine}")
    
    # ==================== æ­¥éª¤ 3: é€é¡µå¤„ç† PDF ====================
    import pdfplumber
    import cv2
    import numpy as np

    pages_data = []
    total_paragraphs = 0
    total_tables = 0
    
    print(f"\n{'='*70}")
    print(f"ğŸ“„ æ­¥éª¤ 3: é€é¡µæå–å†…å®¹ (æ–‡æœ¬ + è¡¨æ ¼ + OCR)")
    print(f"{'='*70}")
        
    with pdfplumber.open(temp_pdf) as pdf:
        page_count = len(pdf.pages)
        print(f"  ğŸ“š æ€»é¡µæ•°: {page_count}")
        
        for page_num, page in enumerate(pdf.pages, 1):
            print(f"\nå¤„ç†ç¬¬ {page_num}/{page_count} é¡µ...")
            
            # ---------------- 3.1 ç”Ÿæˆé¢„è§ˆå›¾ (å‘½åä¿®æ­£ä¸º _300dpi.png ä»¥å…¼å®¹ PDF æµç¨‹) ----------------
            img = page.to_image(resolution=300)
            img_array = np.array(img.original)
            
            # å…³é”®ä¿®æ­£ï¼šå°† preview.png æ”¹ä¸º 300dpi.pngï¼Œè§£å†³å‰ç«¯/å¤§æ¨¡å‹ 404 é—®é¢˜
            preview_image = f"page_{page_num:03d}_300dpi.png"
            preview_path = output_dir / preview_image
            cv2.imwrite(str(preview_path), cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
            print(f"  ğŸ–¼ï¸  é¢„è§ˆå›¾: {preview_image}")
        
            # ---------------- 3.2 æå–æ–‡æœ¬ (High Quality) ----------------
            # layout=True å°è¯•ä¿æŒç‰©ç†å¸ƒå±€
            text_content = page.extract_text(layout=True) or ""
            para_count = len(text_content.split('\n')) if text_content else 0
            total_paragraphs += para_count
            print(f"  ğŸ“ æ–‡æœ¬æå–: {len(text_content)} å­—ç¬¦")
            
            # ---------------- 3.3 æå–è¡¨æ ¼ -> Markdown ----------------
            tables = page.extract_tables()
            table_md_list = []
            if tables:
                print(f"  ğŸ“Š å‘ç°è¡¨æ ¼: {len(tables)} ä¸ª")
                total_tables += len(tables)
                for tbl in tables:
                    md = extract_table_to_markdown(tbl)
                    if md:
                        table_md_list.append(md)
    
            # ---------------- 3.4 ç»„è£…é¡µé¢æ–‡æœ¬ (Text + Tables) ----------------
            final_page_text = text_content
            
            if table_md_list:
                table_section = "\n\nã€è¡¨æ ¼æ•°æ® (Markdown)ã€‘\n" + "\n\n".join(table_md_list)
                # å°†è¡¨æ ¼è¿½åŠ åˆ°æ–‡æœ¬æœ«å°¾ (æˆ–è€…æ ¹æ®ä½ç½®æ’å…¥ï¼Œè¿™é‡Œç®€åŒ–ä¸ºè¿½åŠ )
                final_page_text += table_section
                print(f"    âœ“ å·²è½¬æ¢ {len(table_md_list)} ä¸ªè¡¨æ ¼ä¸º Markdown")
                
            # ---------------- 3.5 OCR è¡¥å…… (é’ˆå¯¹å›¾ç‰‡/æ‰«æä»¶) ----------------
            # åªæœ‰å½“é¡µé¢æ–‡æœ¬å¾ˆå°‘ï¼ˆå¯èƒ½æ˜¯æ‰«æä»¶ï¼‰æ—¶ï¼Œæ‰å¼ºåˆ¶ä¾èµ– OCR æ–‡æœ¬
            # ä½†ä¸ºäº†ä¿é™©ï¼Œæˆ‘ä»¬æ€»æ˜¯è¿è¡Œ OCR ä»¥è·å– bounding box å’Œåº”å¯¹å¤æ‚æƒ…å†µ
            print(f"  ğŸ” è¿è¡Œ OCR...")
            try:
                ocr_result = ocr_extractor.extract_from_image(str(preview_path))
                
                # ä¿å­˜ OCR JSON
                page_ocr_json = output_dir / f"page_{page_num:03d}_ocr.json"
                with open(page_ocr_json, 'w', encoding='utf-8') as f:
                    json.dump(ocr_result, f, ensure_ascii=False, indent=2)
                    
                # ç”Ÿæˆå¯è§†åŒ–
                vis_path = output_dir / f"page_{page_num:03d}_visualized.png"
                visualize_extraction(str(preview_path), str(page_ocr_json), str(vis_path))
                
                # æå– OCR æ–‡æœ¬
                ocr_text_blocks = ocr_result.get('text_blocks', [])
                ocr_texts = [b.get('text', '') for b in ocr_text_blocks if b.get('text', '').strip()]
                ocr_full_text = "\n".join(ocr_texts)
                
                # æ™ºèƒ½åˆå¹¶ç­–ç•¥ï¼š
                # å¦‚æœç›´æ¥æå–çš„æ–‡æœ¬å¾ˆå°‘ï¼Œè¯´æ˜å¯èƒ½æ˜¯çº¯å›¾ï¼Œä½¿ç”¨ OCR æ–‡æœ¬ä½œä¸ºä¸»åŠ›
                if len(text_content) < 50 and len(ocr_full_text) > 50:
                    print("    âš ï¸  é¡µé¢æ–‡æœ¬æå°‘ï¼Œé‡‡ç”¨ OCR ç»“æœä¸ºä¸»")
                    final_page_text = f"{final_page_text}\n\nã€OCR è¯†åˆ«å†…å®¹ã€‘\n{ocr_full_text}"
                else:
                    # å¦åˆ™ä½œä¸ºè¡¥å……
                    final_page_text += f"\n\nã€è§†è§‰è¯†åˆ«è¡¥å…… (OCR)ã€‘\n{ocr_full_text}"
                    
                avg_confidence = 0.0
                if ocr_text_blocks:
                    confs = [b.get('confidence', 0) for b in ocr_text_blocks]
                    avg_confidence = sum(confs) / len(confs)
                    
            except Exception as e:
                print(f"  âŒ OCR å‡ºé”™: {e}")
                ocr_text_blocks = []
                avg_confidence = 0.0

            # ---------------- 3.6 æ„å»º Page Data ----------------
            page_data = {
                "page_number": page_num,
                "statistics": {
                    "total_characters": len(final_page_text),
                    "total_tables": len(tables),
                    "avg_ocr_confidence": round(avg_confidence, 3)
                },
                "stage1_global": {
                    "image": preview_image,
                    "text_source": "pdfplumber+ocr"
                },
                "stage3_vlm": {
                    "text_combined": final_page_text
                }
            }
            pages_data.append(page_data)

    # ==================== æ­¥éª¤ 4: ç”Ÿæˆè¾“å‡ºæ–‡ä»¶ ====================
    
    # 1. complete_adaptive_ocr.json (å…¼å®¹æ—§æ ¼å¼)
    result = {
        "source_file": str(docx_path),
        "file_type": "docx",
        "total_pages": page_count,
        "ocr_engine": ocr_engine,
        "pages": pages_data,
        "statistics": {
            "total_paragraphs": total_paragraphs,
            "total_tables": total_tables
        }
    }
    
    complete_json = output_dir / "complete_adaptive_ocr.json"
    with open(complete_json, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # 2. complete_document.json (ES ç´¢å¼•æ ¼å¼)
    pages_for_index = []
    for page in pages_data:
        page_num = page['page_number']
        text_combined = page['stage3_vlm']['text_combined']
        image_filename = page['stage1_global']['image']
        
        pages_for_index.append({
            'page_number': page_num,
            'image_path': str(output_dir / image_filename),
            'image_filename': image_filename,
            'content': {
                'full_text_cleaned': text_combined,
                'full_text_raw': text_combined,
                'key_fields': [],
                'tables': [] # ç»“æ„åŒ–æ•°æ®åç»­å¯æ‰©å±•
            },
            'ocr_data': {
                'text_blocks': []
            },
            'metadata': {
                'extraction_method': 'docx_via_pdfplumber',
                'ocr_engine': ocr_engine,
                'avg_ocr_confidence': page['statistics']['avg_ocr_confidence'],
                'vlm_refined': False
            }
        })
        
    complete_document_path = output_dir / "complete_document.json"
    with open(complete_document_path, 'w', encoding='utf-8') as f:
        json.dump({'pages': pages_for_index}, f, ensure_ascii=False, indent=2)

    # æ¸…ç†ä¸´æ—¶ PDF
    if temp_pdf.exists():
        temp_pdf.unlink()
        
    print(f"\n{'='*70}")
    print(f"âœ… å¤„ç†å®Œæˆ (æ–¹æ¡ˆB)")
    print(f"ğŸ“Š ç»Ÿè®¡: {page_count} é¡µ, {total_tables} ä¸ªè¡¨æ ¼")
    print(f"ğŸ“‚ è¾“å‡º: {output_dir}")
    print(f"{'='*70}")
    
    return result

def main():
    parser = argparse.ArgumentParser(description='Process DOCX via PDF conversion')
    parser.add_argument('docx_file', help='Path to DOCX file')
    parser.add_argument('-o', '--output', help='Output directory', default=None)
    parser.add_argument('--ocr-engine', choices=['easy', 'paddle', 'vision'], 
                       default='paddle', help='OCR engine to use')
    
    args = parser.parse_args()
    
    docx_path = Path(args.docx_file)
    if not docx_path.exists():
        print(f"Error: File not found: {docx_path}")
        return 1
    
    if args.output:
        output_dir = Path(args.output)
    else:
        output_dir = Path(f"{docx_path.stem}_docx_processed")
    
    try:
        process_docx(docx_path, output_dir, args.ocr_engine)
        return 0
    except Exception as e:
        print(f"âŒ Fatal Error: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == '__main__':
    sys.exit(main())

#!/usr/bin/env python3
"""
ä½¿ç”¨VLMæ¨¡å‹ä¼˜åŒ–OCRç»“æœï¼Œç”Ÿæˆé€‚åˆESæ£€ç´¢çš„è§„èŒƒåŒ–JSON
æ”¯æŒLM Studioæœ¬åœ°éƒ¨ç½²çš„æ¨¡å‹
"""
import os
import sys
import json
import base64
import argparse
from pathlib import Path
from typing import Dict, Any, List
from openai import OpenAI


class VLMRefiner:
    """ä½¿ç”¨VLMæ¨¡å‹ä¼˜åŒ–OCRç»“æœ"""
    
    def __init__(self, api_base: str = "http://localhost:1234/v1", api_key: str = "lm-studio"):
        """
        åˆå§‹åŒ–VLMç²¾ç‚¼å™¨
        
        Args:
            api_base: LM Studio APIåœ°å€
            api_key: APIå¯†é’¥ï¼ˆLM Studioé»˜è®¤ä¸éœ€è¦ï¼‰
        """
        self.client = OpenAI(base_url=api_base, api_key=api_key)
        print(f"âœ“ Connected to LM Studio at {api_base}")
    
    def encode_image_base64(self, image_path: str) -> str:
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        with open(image_path, 'rb') as f:
            return base64.b64encode(f.read()).decode('utf-8')
    
    def build_prompt(self, ocr_data: Dict[str, Any], page_number: int = 1, region_ocr_data: List[Dict[str, Any]] = None) -> str:
        """æ„å»ºæç¤ºè¯ - é’ˆå¯¹æ¯ä¸€é¡µçš„ç†è§£å’Œæå–"""
        full_text = ocr_data.get('full_text', '')
        text_blocks_count = ocr_data.get('text_blocks_count', 0)
        avg_confidence = ocr_data.get('average_confidence', 0) * 100
        
        # æ„å»ºåŒºåŸŸOCRä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        region_info = ""
        if region_ocr_data:
            region_info = "\n\n**Enhanced OCR from High-Resolution Regions (600 DPI):**\n"
            region_info += f"We also performed zoom-in OCR on {len(region_ocr_data)} low-confidence regions at 600 DPI.\n"
            region_info += "These regions had unclear text in the global 300 DPI scan, so we re-scanned them at higher resolution:\n\n"
            
            for i, region in enumerate(region_ocr_data, 1):
                region_text = region.get('full_text', '').strip()
                region_conf = region.get('average_confidence', 0) * 100
                region_bbox = region.get('bbox_300dpi', [0, 0, 0, 0])
                
                if region_text:
                    region_info += f"Region {i} (bbox: {region_bbox}):\n"
                    region_info += f"  Confidence: {region_conf:.1f}%\n"
                    region_info += f"  Text: {region_text[:300]}{'...' if len(region_text) > 300 else ''}\n\n"
            
            region_info += "Note: Use these high-resolution texts as REFERENCE only. Your primary analysis should be based on what YOU SEE in the image.\n"
        
        prompt = f"""You are an expert document analyzer with vision understanding capabilities.

**Task:** Analyze this document page (Page {page_number}) comprehensively - both WHAT YOU SEE in the image and WHAT THE TEXT SAYS.

**OCR Extracted Text (300 DPI Global Scan):**
{full_text}

**OCR Statistics:**
- Text blocks: {text_blocks_count}
- Average confidence: {avg_confidence:.1f}%{region_info}

**Your Analysis Must Include:**

1. **Visual Page Description** (Most Important!)
   - Describe what you SEE in this page image (layout, structure, visual elements)
   - What type of page is this? (title page / data table / diagram / form / mixed content)
   - What is the PURPOSE of this page in the document?
   - Note visual elements: tables, diagrams, stamps, signatures, logos, borders, etc.

2. **Content Understanding**
   - Fix OCR errors (e.g., "4-AU9-25" â†’ "4-Aug-25", "ä¼› SeP 3" â†’ "15-Sep-25")
   - Clean up garbled text
   - Extract key information based on what's visible

3. **Structured Data Extraction**
   - Document metadata (if visible on this page)
   - Tables (describe structure and content)
   - Technical specifications
   - Any domain-specific information (project, equipment, revisions, etc.)

**Output Format:**
Respond ONLY with a valid JSON object:
```json
{{
  "page_analysis": {{
    "page_number": {page_number},
    "page_type": "title_page | data_table | diagram | text_content | form | mixed",
    "page_description": "50-150 words describing what this page IS and what you SEE in the image",
    "visual_elements": ["table", "stamp", "logo", "etc"],
    "layout_structure": "Brief description of visual layout"
  }},
  
  "extracted_content": {{
    "full_text_cleaned": "Corrected and cleaned text from OCR",
    "key_fields": [
      {{"field": "field_name", "value": "field_value"}}
    ],
    "tables": [
      {{"description": "what this table contains", "rows": 0, "cols": 0}}
    ]
  }},
  
  "document_metadata": {{
    "document_id": "string or null",
    "document_type": "string or null", 
    "revision": "string or null",
    "title": "string or null"
  }},
  
  "domain_specific": {{
    "project": {{"name": "...", "plant": "...", "phase": "..."}} or null,
    "equipment": {{"tag": "...", "name": "...", "unit": "..."}} or null,
    "revisions": [...] or null
  }},
  
  "keywords": ["keyword1", "keyword2"],
  "confidence": 0.0-1.0,
  "notes": ["any uncertainties or observations"]
}}
```

**Critical:** The page_description must describe WHAT YOU SEE in the image, not just repeat OCR text!

Respond with ONLY the JSON, no additional text."""

        return prompt
    
    def refine_with_image(self, image_path: str, ocr_json_path: str, 
                          model: str = None, page_number: int = 1, 
                          region_ocr_results: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨VLMæ¨¡å‹å’Œå›¾ç‰‡ä¼˜åŒ–OCRç»“æœ
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            ocr_json_path: OCRç»“æœJSONè·¯å¾„
            model: æ¨¡å‹åç§°ï¼ˆNoneåˆ™ä½¿ç”¨LM StudioåŠ è½½çš„æ¨¡å‹ï¼‰
            page_number: é¡µç ï¼ˆç”¨äºpromptï¼‰
            region_ocr_results: é˜¶æ®µ3çš„é«˜åˆ†è¾¨ç‡åŒºåŸŸOCRç»“æœåˆ—è¡¨
            
        Returns:
            ç²¾ç‚¼åçš„ç»“æ„åŒ–æ•°æ®
        """
        print(f"\nğŸ“„ Processing Page {page_number}: {os.path.basename(image_path)}")
        
        # è¯»å–OCRç»“æœ
        with open(ocr_json_path, 'r', encoding='utf-8') as f:
            ocr_data = json.load(f)
        
        # ç¼–ç å›¾ç‰‡
        print("ğŸ–¼ï¸  Encoding image...")
        image_base64 = self.encode_image_base64(image_path)
        
        # æ„å»ºæç¤ºè¯ï¼ˆåŒ…å«åŒºåŸŸOCRæ•°æ®ï¼‰
        if region_ocr_results:
            print(f"ğŸ“ Including {len(region_ocr_results)} high-resolution region OCR results")
        prompt = self.build_prompt(ocr_data, page_number, region_ocr_results)
        
        # å‡†å¤‡æ¶ˆæ¯ï¼ˆæ”¯æŒvisionï¼‰
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_base64}"
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ]
        
        print("ğŸ¤– Calling VLM model...")
        print("   (This may take a while for vision models...)")
        
        try:
            # è°ƒç”¨æ¨¡å‹
            response = self.client.chat.completions.create(
                model=model if model else "local-model",
                messages=messages,
                max_tokens=4096,
                temperature=0.1,
            )
            
            content = response.choices[0].message.content
            print("âœ“ Model response received")
            
            # è§£æJSONå“åº”ï¼ˆå¢å¼ºé²æ£’æ€§ï¼‰
            json_start = content.find("{")
            json_end = content.rfind("}") + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = content[json_start:json_end]
                
                # å°è¯•å¤šç§è§£æç­–ç•¥
                for attempt in range(3):
                    try:
                        if attempt == 0:
                            # ç›´æ¥è§£æ
                            refined_data = json.loads(json_str)
                        elif attempt == 1:
                            # ä¿®å¤å¸¸è§çš„è½¬ä¹‰é—®é¢˜ï¼šå°†å•ä¸ªåæ–œæ æ›¿æ¢ä¸ºåŒåæ–œæ ï¼ˆé™¤äº†å·²ç»æ­£ç¡®è½¬ä¹‰çš„ï¼‰
                            import re
                            # ä¿æŠ¤å·²ç»æ­£ç¡®è½¬ä¹‰çš„å­—ç¬¦
                            fixed_json = re.sub(r'\\(?!["\\/bfnrtu])', r'\\\\', json_str)
                            refined_data = json.loads(fixed_json)
                            print("   â„¹ï¸  Fixed invalid escape sequences")
                        elif attempt == 2:
                            # ä½¿ç”¨strict=Falseæ¨¡å¼
                            refined_data = json.loads(json_str, strict=False)
                            print("   â„¹ï¸  Parsed with strict=False mode")
                        
                        # è§£ææˆåŠŸ
                        return refined_data
                        
                    except json.JSONDecodeError as e:
                        if attempt < 2:
                            continue  # å°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥
                        else:
                            # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œè®°å½•è¯¦ç»†é”™è¯¯
                            print(f"âš ï¸  JSON parse failed after {attempt+1} attempts: {e}")
                            print(f"   Error position: line {e.lineno}, column {e.colno}")
                            print(f"   Problematic section: ...{json_str[max(0,e.pos-50):e.pos+50]}...")
                            raise ValueError(f"Failed to parse VLM JSON response: {e}")
            else:
                raise ValueError("No valid JSON found in model response")
            
            return refined_data
            
        except Exception as e:
            print(f"âš ï¸  Error calling VLM model: {e}")
            print("   Falling back to text-only refinement...")
            return self.refine_text_only(ocr_data, model)
    
    def refine_text_only(self, ocr_data: Dict[str, Any], model: str = None) -> Dict[str, Any]:
        """
        ä»…ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ä¼˜åŒ–OCRç»“æœï¼ˆå½“visionä¸å¯ç”¨æ—¶ï¼‰
        
        Args:
            ocr_data: OCRç»“æœæ•°æ®
            model: æ¨¡å‹åç§°
            
        Returns:
            ç²¾ç‚¼åçš„ç»“æ„åŒ–æ•°æ®
        """
        print("ğŸ“ Using text-only mode...")
        
        prompt = self.build_prompt(ocr_data)
        
        try:
            response = self.client.chat.completions.create(
                model=model if model else "local-model",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=4096,
                temperature=0.1,
            )
            
            content = response.choices[0].message.content
            
            # è§£æJSONï¼ˆä½¿ç”¨å¢å¼ºçš„é²æ£’æ€§è§£æï¼‰
            json_start = content.find("{")
            json_end = content.rfind("}") + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = content[json_start:json_end]
                
                # å°è¯•å¤šç§è§£æç­–ç•¥
                for attempt in range(3):
                    try:
                        if attempt == 0:
                            refined_data = json.loads(json_str)
                        elif attempt == 1:
                            import re
                            fixed_json = re.sub(r'\\(?!["\\/bfnrtu])', r'\\\\', json_str)
                            refined_data = json.loads(fixed_json)
                            print("   â„¹ï¸  Fixed invalid escape sequences (text-only mode)")
                        elif attempt == 2:
                            refined_data = json.loads(json_str, strict=False)
                            print("   â„¹ï¸  Parsed with strict=False mode (text-only)")
                        
                        return refined_data
                        
                    except json.JSONDecodeError as e:
                        if attempt < 2:
                            continue
                        else:
                            raise ValueError(f"Failed to parse JSON after {attempt+1} attempts: {e}")
            else:
                raise ValueError("No valid JSON found in model response")
            
        except Exception as e:
            print(f"âŒ Text-only refinement failed: {e}")
            # è¿”å›åŸºç¡€ç»“æ„
            return {
                "document_metadata": {},
                "document_content": {},
                "revision_history": [],
                "procedures": {},
                "keywords": [],
                "full_text_cleaned": ocr_data.get('full_text', ''),
                "extraction_notes": [f"Error during refinement: {str(e)}"]
            }
    
    def create_page_vlm_document(self, refined_data: Dict[str, Any], 
                                  ocr_data: Dict[str, Any],
                                  image_path: str, page_number: int) -> Dict[str, Any]:
        """
        åˆ›å»ºåŒ…å«OCRå’ŒVLMç»“æœçš„å®Œæ•´é¡µé¢æ–‡æ¡£
        
        Args:
            refined_data: VLMç²¾ç‚¼åçš„æ•°æ®
            ocr_data: åŸå§‹OCRæ•°æ®
            image_path: å›¾ç‰‡è·¯å¾„
            page_number: é¡µç 
            
        Returns:
            å®Œæ•´çš„é¡µé¢æ–‡æ¡£ç»“æ„
        """
        # æå–VLMåˆ†æç»“æœ
        page_analysis = refined_data.get('page_analysis', {})
        extracted_content = refined_data.get('extracted_content', {})
        doc_metadata = refined_data.get('document_metadata', {})
        domain_specific = refined_data.get('domain_specific', {})
        
        # æ„å»ºå®Œæ•´é¡µé¢æ–‡æ¡£
        page_doc = {
            # ===== é¡µé¢åŸºç¡€ä¿¡æ¯ =====
            "page_number": page_number,
            "image_path": os.path.abspath(image_path),
            "image_filename": os.path.basename(image_path),
            
            # ===== VLMé¡µé¢åˆ†æï¼ˆæ–°å¢ï¼ï¼‰=====
            "page_analysis": {
                "page_type": page_analysis.get('page_type', 'unknown'),
                "page_description": page_analysis.get('page_description', ''),
                "visual_elements": page_analysis.get('visual_elements', []),
                "layout_structure": page_analysis.get('layout_structure', '')
            },
            
            # ===== æ–‡æœ¬å†…å®¹ =====
            "content": {
                "full_text_raw": ocr_data.get('full_text', ''),
                "full_text_cleaned": extracted_content.get('full_text_cleaned', ''),
                "key_fields": extracted_content.get('key_fields', []),
                "tables": extracted_content.get('tables', [])
            },
            
            # ===== åŸå§‹OCRæ•°æ® =====
            "ocr_data": {
                "text_blocks": ocr_data.get('text_blocks', []),
                "text_blocks_count": ocr_data.get('text_blocks_count', 0),
                "average_confidence": ocr_data.get('average_confidence', 0),
                "image_size": ocr_data.get('image_size', {}),
                "layout_regions": ocr_data.get('layout_regions', [])
            },
            
            # ===== æå–çš„å…ƒæ•°æ® =====
            "metadata": doc_metadata,
            
            # ===== é¢†åŸŸç‰¹å®šä¿¡æ¯ =====
            "domain_data": domain_specific,
            
            # ===== æœç´¢å…³é”®è¯ =====
            "keywords": refined_data.get('keywords', []),
            
            # ===== VLMç½®ä¿¡åº¦å’Œæ³¨é‡Š =====
            "vlm_metadata": {
                "confidence": refined_data.get('confidence', 0.0),
                "extraction_notes": refined_data.get('notes', [])
            }
        }
        
        return page_doc


def main():
    # Load default configuration from config.yaml
    try:
        import sys
        from pathlib import Path
        # Add parent directory to path to import config
        sys.path.insert(0, str(Path(__file__).parent.parent))
        from src.config import config
        vision_cfg = config.vision_config
        default_api_base = vision_cfg.get('api_url', 'http://localhost:1234/v1')
        default_model = vision_cfg.get('model_name', 'google/gemma-3-27b')
        config_loaded = True
    except ImportError:
        default_api_base = 'http://localhost:1234/v1'
        default_model = 'google/gemma-3-27b'
        config_loaded = False
    
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨VLMæ¨¡å‹ä¼˜åŒ–OCRç»“æœï¼Œç”ŸæˆESå‹å¥½çš„JSON"
    )
    parser.add_argument("image", help="å›¾ç‰‡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("ocr_json", help="OCRç»“æœJSONè·¯å¾„")
    parser.add_argument("-o", "--output", help="è¾“å‡ºJSONè·¯å¾„ï¼ˆé»˜è®¤ï¼šxxx_vlm.jsonï¼‰")
    parser.add_argument("-p", "--page-number", type=int, default=1, 
                       help="é¡µç ï¼ˆç”¨äºVLMç†è§£ï¼Œé»˜è®¤ï¼š1ï¼‰")
    parser.add_argument("-r", "--regions-json", 
                       help="é˜¶æ®µ3åŒºåŸŸOCRç»“æœJSONè·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--api-base", default=default_api_base,
                       help=f"LM Studio APIåœ°å€ï¼ˆé»˜è®¤ä»config: {default_api_base}ï¼‰")
    parser.add_argument("--model", default=default_model,
                       help=f"æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä»config: {default_model}ï¼‰")
    parser.add_argument("--text-only", action="store_true",
                       help="ä»…ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ï¼ˆä¸å‘é€å›¾ç‰‡ï¼‰")
    parser.add_argument("--pretty", action="store_true",
                       help="è¾“å‡ºå¯è¯»æ€§æ ¼å¼")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    image_path = Path(args.image)
    ocr_json_path = Path(args.ocr_json)
    
    if not image_path.exists():
        print(f"âŒ Error: Image not found: {image_path}")
        return 1
    
    if not ocr_json_path.exists():
        print(f"âŒ Error: OCR JSON not found: {ocr_json_path}")
        return 1
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = image_path.with_stem(image_path.stem + "_vlm").with_suffix('.json')
    
    print("="*80)
    print(f"ğŸš€ VLM Page Analysis (Page {args.page_number})")
    print("="*80)
    if config_loaded:
        print(f"âœ“ Configuration loaded from config.yaml")
    else:
        print(f"âš  Using default configuration (config.yaml not found)")
    print(f"Model: {args.model}")
    print(f"API: {args.api_base}")
    print("="*80)
    
    try:
        # åˆå§‹åŒ–ç²¾ç‚¼å™¨
        refiner = VLMRefiner(api_base=args.api_base)
        
        # è¯»å–OCRæ•°æ®
        with open(ocr_json_path, 'r', encoding='utf-8') as f:
            ocr_data = json.load(f)
        
        # è¯»å–åŒºåŸŸOCRæ•°æ®ï¼ˆå¦‚æœæä¾›ï¼‰
        region_ocr_results = None
        if args.regions_json:
            regions_path = Path(args.regions_json)
            if regions_path.exists():
                with open(regions_path, 'r', encoding='utf-8') as f:
                    region_ocr_results = json.load(f)
                print(f"âœ“ Loaded {len(region_ocr_results)} region OCR results")
            else:
                print(f"âš  Warning: Regions JSON not found: {regions_path}")
        
        # ç²¾ç‚¼æ•°æ®
        if args.text_only:
            refined_data = refiner.refine_text_only(ocr_data, args.model)
        else:
            refined_data = refiner.refine_with_image(
                str(image_path), 
                str(ocr_json_path),
                args.model,
                args.page_number,
                region_ocr_results
            )
        
        print("\nâœ“ VLM analysis completed")
        
        # åˆ›å»ºå®Œæ•´é¡µé¢æ–‡æ¡£
        print("ğŸ“¦ Creating complete page document...")
        page_doc = refiner.create_page_vlm_document(
            refined_data, ocr_data, str(image_path), args.page_number
        )
        
        # ä¿å­˜ç»“æœ
        print(f"ğŸ’¾ Saving to: {output_path}")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(page_doc, f, ensure_ascii=False, indent=2 if args.pretty else None)
        
        print("\n" + "="*80)
        print("âœ… SUCCESS!")
        print("="*80)
        
        # æ‰“å°æ‘˜è¦
        if args.pretty:
            print("\nğŸ“‹ Page Analysis Summary:")
            print(f"  Page Number: {page_doc.get('page_number', 'N/A')}")
            print(f"  Page Type: {page_doc.get('page_analysis', {}).get('page_type', 'N/A')}")
            print(f"  Description: {page_doc.get('page_analysis', {}).get('page_description', 'N/A')[:100]}...")
            print(f"  Visual Elements: {', '.join(page_doc.get('page_analysis', {}).get('visual_elements', []))}")
            print(f"  Keywords: {', '.join(page_doc.get('keywords', [])[:5])}")
            print(f"  OCR Confidence: {page_doc.get('ocr_data', {}).get('average_confidence', 0):.2f}")
            print(f"  VLM Confidence: {page_doc.get('vlm_metadata', {}).get('confidence', 0):.2f}")
        
        print(f"\nğŸ“ Output: {output_path}")
        return 0
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())

